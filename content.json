[{"title":"语往昔","date":"2020-02-01T01:31:22.000Z","path":"2020/02/01/语往昔/","text":"吞一座山，饮一片湖！ 来！ 比谁！ ​ 凉心 昨夜春风入梦来，倾盆一洗往昔念。 梨花点水红烛尽，竹叶凉心碧水新。 ​ 登玉龙高山巍峨过千尺，平地危立览群峰。白雪皑皑尽天色，青石叠叠通神宫。红日初升攀玉龙，似有冰灵悬明珠。南国秀丽好风景，山河锦绣美如画。 ​ 觅佳人天生碧瑜岂无暇？柳畔佳人伴生痣。回眸一笑群芳争，半步生莲香草摇。明眸生辉照明月，双靥点水荡涟漪。惶惶乎得见其影，寻寻觅觅觅寻寻。 宛若桃花竞开，满地扑香。群蝶来慕，痴痴如醉；踏清风来至，环芬芳齐舞。天生异香何物。窈窕身影飞舞。 青白色石阶，坐落在蜿蜒河流的江畔。不知从何而来，石阶上的棱角，早已磨平，被江水？被时间？被孤独？就坐在这吧。请用此身所有换我一杯凉茶，可好？ ​ 路人由那樱花飞舞吧，静美的让时间忘却呼吸。小狗欢快肆意的奔走着。小鸟就叽叽喳喳的叫吧。这条直长的路，这道细腻的光，是命运的邂逅吗？从未觉察过的你，是路人吗？ ​ 早安夜匆匆忙，匆匆忙的来过。天色微带朦胧的醒来，四野的街灯，延成两条金色巨龙，至远方。初觉的红日，在光彩中升起，早安，我的城市。 ​ 尽逍遥数载终尽空，风华一世又若何。叶叹秋景竞悲凉，风话冬雪近苍穹。红烛旧窗佳人泪，孤山残碑英雄冢。言笑时高楼瞬起，恍惚间人世沧桑。 ​ 壮志歌解花三千多，读书四万少。平白添忧愁，竖中含辛累。斩却千般苦，不如不来世。既来为男儿，无中生勇志。大椿万载寿，吾辈百年耳。虽有憾时岁，心无形所缚。高歌九龙台，举剑苍穹间。枪舞古凰坠，剑启天龙啸。彼岸花有言，今朝不去语。往昔忆尤清，浅笑赏明月。来回九十九，今夕要补一。人生有难事，万般皆一般。唯一恒亘古，此意藏于心。 ​ 勉琵琶轻弹战火燃，浊酒未饮刀剑启。他乡月下梦故土，茅庐石坡应犹在。身被青衣览群雄，立足赤壁看古今。激情怎负少年时，昂首笑看往昔颓。 当悦耳的琴声穿过树梢间的缝隙知了也不再低鸣雨点悄然渗进地面不带涟漪便拨动我的心海清晰而模糊的印出我梦中那个女孩那个微笑总不觉挂在嘴角的女孩我匆匆忙的离去只留下发了呆的知了忘了声响","tags":[{"name":"点滴","slug":"点滴","permalink":"http://yoursite.com/tags/点滴/"}]},{"title":"落星","date":"2020-02-01T01:30:28.000Z","path":"2020/02/01/落星/","text":"​ 烦忧​ ——戴望舒 说是寂寞的秋的清愁，说是辽远的海的相思。假如有人问我的烦忧，我不敢说出你的名字。 我不敢说出你的名字。假如有人问我的烦忧，说是辽远的海的相思。说是寂寞的秋的清愁 ​ 《青春》 ​ 文/塞缪尔·厄尔曼 青春不是年华，而是心境；青春不是桃面、丹唇、柔膝，而是深沉的意志，恢宏的想象，炙热的恋情；青春是生命的深泉在涌流。 青春气贯长虹，勇锐盖过怯弱，进取压倒苟安。如此锐气，二十后生而有之，六旬男子则更多见。年岁有加，并非垂老，理想丢弃，方堕暮年。 岁月悠悠，衰微只及肌肤；热忱抛却，颓废必致灵魂。忧烦，惶恐，丧失自信，定使心灵扭曲，意气如灰。 无论年届花甲，拟或二八芳龄，心中皆有生命之欢乐，奇迹之诱惑，孩童般天真久盛不衰。人人心中皆有一台天线，只要你从天上人间接受美好、希望、欢乐、勇气和力量的信号，你就青春永驻，风华常存。 一旦天线下降，锐气便被冰雪覆盖，玩世不恭、自暴自弃油然而生，即使年方二十，实已垂垂老矣；然则只要树起天线，捕捉乐观信号，你就有望在八十高龄告别尘寰时仍觉年轻。 去不该去的地方，做不该做的事情，这也是勇气啊！ ——《侠肝义胆沈剑心》（2019.04.19）","tags":[{"name":"点滴","slug":"点滴","permalink":"http://yoursite.com/tags/点滴/"}]},{"title":"成就：我上王者了！","date":"2020-01-04T06:07:30.000Z","path":"2020/01/04/成就：我上王者了！/","text":"第一次在有排位系统的游戏上荣登王者段位 很开心~ 2020年1月4日《王者荣耀》","tags":[{"name":"点滴","slug":"点滴","permalink":"http://yoursite.com/tags/点滴/"},{"name":"成就","slug":"成就","permalink":"http://yoursite.com/tags/成就/"}]},{"title":"Deepin 系统优化","date":"2019-07-26T07:17:12.000Z","path":"2019/07/26/Deepin-系统优化/","text":"一 . 修改系统默认编辑器系统默认编辑器是：nano 1234# 打开Terminal，输入以下指令：sudo update-alternatives --config editor# 输入所要变更的编辑器的编号（Terminal上会有提示） 为方便复制粘贴，修改Terminal的设置。点击Terminal右上角菜单标志——设置。 将终端中复制粘贴的快捷键设置为 Ctrl+C 和 Ctrl+V 。 将终端中搜索的快捷键设置为 Ctrl+F 。 将终端中放大缩小的快捷键设置为 Ctrl+N 和 Ctrl+M 。 将光标中“选中光标时自动复制到剪切板”选项勾上。 二 . 设置sudo不用输入密码12345# 打开Terminal，输入以下指令：sudo visudo# 在编辑器中更换\"%admin ALL=(ALL) ALL\"为以下指令：%admin ALL=(ALL) NOPASSWD: ALL 三 . CPU优化问题：Deepin Linux 15.10升级后CPU不会自动降频造成过热 123456789101112# 打开Terminal，输入以下指令：sudo gedit /etc/default/grub# 编辑grub文件，其中两行改为如下：GRUB_CMDLINE_LINUX=\"splash quiet \"GRUB_CMDLINE_LINUX_DEFAULT=\"intel_pstate=disable\"# 保存退出后更新一下grubsudo update-grub# 然后，重启系统。sudo reboot 四 . 修改WIFI配置文件问题：Deepin 15.8/Ubuntu 18.04用intel无线网卡速度跑不满 12345678# 打开Terminal，输入以下指令：sudo vim /etc/modprobe.d/iwlwifi.conf# 然后把iwlwifi.conf里面的11n_disable=1改成11n_disable=8# 保存并重新启动sudo reboot 五 . 镜像源（Apt软件源）的修改123456789# 打开Terminal，输入以下指令：sudo vim /etc/apt/sources.list# 在编辑器中更换 http://packages.deepin.com 为 https://mirrors.tuna.tsinghua.edu.cn# 更新sudo apt-get updatesudo apt-get upgrade 此外，deepin或是其他Linux（APT）系统中可能无法使用 add-apt-repository 命令。请执行以下操作，确保该命令能够被使用： 1234567# 使用以下两个安装命令（旧系统版本使用第一条，新版使用第二条）sudo apt-get install python-software-propertiessudo apt-get install software-properties-common# 更新sudo apt-get updatesudo apt-get upgrade 六 . 安装pip并修改pip源1234567891011# 安装pip和pip3：sudo apt install -y python-pip python3-pip# 更换pip源（以下更改用户pip源，若希望全局有效，直接 sudo vim /etc/pip.conf ）cd ~sudo mkdir .pipsudo vim .pip/pip.conf# 添加以下内容至pip.conf文件[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple 七. 登录和唤醒免密 设置自动免密登录 点击设置——账户——example（你的账户）将”自动登录”开关打开（勾上清空钥匙串密码）将”无密码登录”开关打开（勾上清空钥匙串密码） 设置唤醒免密 点击设置——电源管理将”唤醒显示器时需要密码”开关关闭将”待机恢复时需要密码”开关关闭 八. 常用商店软件 搜狗输入法 百度网盘 迅雷 微信 QQ VS Code Annaconda 九 . 命令行软件 安装Git123sudo apt-get install gitgit config --global user.email \"464306924@qq.com\"git config --global user.name \"messj-0508\" 设置GitHub的ssh 连接，参考《GitHub设置无密码登录》 2.安装Typora 下载二进制免安装包 解压缩到用户目录下 添加指令路径 123456789# Terminalsudo vim .bashrc# vim 在最后补充两句export PATH=$PATH:~/Typoraalias typora='Typora'# Terminal（重新加载bash配置）source .bashrc 添加菜单启动项（可选） 1234567891011121314# Terminalcd /usr/share/applicationssudo vim Typora.desktop# Vim[Desktop Entry]Version=1.0 # 版本号Name=Typora # 将要在启动器显示的名字Comment=a markdown editor # 说明Exec=/xx/xx/Typora # 可执行程序路径，一定要是完整的绝对路径Icon=/xx/xx.png # 程序图标Terminal=false Type=Application Categories=Editor; 安装nodejs和npm（可选，hexo博客需要） 123456789101112sudo apt install nodejs-legacysudo apt install nodesudo apt install nodejs-binsudo npm install -g nsudo npm install hexo-cli -gcd ~/Desktopgit clone git@github.com:messj-0508/messj-0508.github.io.git hexocd hexonpm install 十 . VS Code 配置优化","tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/tags/Ubuntu/"},{"name":"Tutorial","slug":"Tutorial","permalink":"http://yoursite.com/tags/Tutorial/"}]},{"title":"Markdown tutorial","date":"2019-05-03T08:34:25.000Z","path":"2019/05/03/Markdown-tutorial/","text":"Markdown是一种常用的标记语言，类似于html语言。许多博客都支持md格式，同时该语言也被github支持。 优点： 1、简洁、无需排版。 2、操作简单。 缺点： 1、需要记一些语法。 2、排版、格式有限。 以下笔记总结于两篇博客，如下： https://www.jianshu.com/p/191d1e21f7ed https://www.jianshu.com/p/2df05f279331 一、标题在标题前加#即表示该段文字是标题。一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 示例： 123456# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 效果： ![1553769689177](1553769689177.png) 二、字体加粗要加粗的文字左右分别用两个*号包起来 斜体要倾斜的文字左右分别用一个*号包起来 斜体加粗要倾斜和加粗的文字左右分别用三个*号包起来 删除线要加删除线的文字左右分别用两个~~号包起来 示例： 1234**这是加粗的文字***这是倾斜的文字*`***这是斜体加粗的文字***~~这是加删除线的文字~~ 效果： 这是加粗的文字这是倾斜的文字这是斜体加粗的文字这是加删除线的文字 三、分割线三个或以上的-或是*即可 示例： 1234-------******** 四、图片语法： 1234![图片alt](图片地址 ''图片title'')图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： 1![图片加载失败](1553769689177.png \"效果图\") 五、超链接语法： 12[超链接名](超链接地址 \"超链接title\")title可加可不加 示例： 1[百度](http://baidu.com) 效果如下：百度 注：Markdown本身语法不支持链接在新页面中打开，貌似简书做了处理，是可以的。别的平台可能就不行了，如果想要在新页面中打开的话可以用html语言的a标签代替。 六、表格如果格式选择默认则按以下 语法： 1234| 一个普通标题 | 一个普通标题 | 一个普通标题 || ------ | ------ | ------ || 短文本 | 中等文本 | 稍微长一点的文本 || 稍微长一点的文本 | 短文本 | 中等文本 | 效果： 一个普通标题 一个普通标题 一个普通标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 注：一些编辑器、解读器，表格的语句上一行必须为空行，不然表格不生效。 如果有左右对齐的需求则按以下 Markdown 代码: 1234| 左对齐标题 | 右对齐标题 | 居中对齐标题 || :------| ------: | :------: || 短文本 | 中等文本 | 稍微长一点的文本 || 稍微长一点的文本 | 短文本 | 中等文本 | 效果如下： 左对齐标题 右对齐标题 居中对齐标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 七、代码语法： 单行代码：代码之间分别用一个反引号包起来 1`代码内容` 代码块：代码之间分别用三个反引号包起来，且两边的反引号单独占一行 12345(```) 代码... 代码... 代码...(```) 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。","tags":[{"name":"Tutorial","slug":"Tutorial","permalink":"http://yoursite.com/tags/Tutorial/"}]},{"title":"subsystem of Windows-System:Ubuntu16.04","date":"2019-05-03T06:31:53.000Z","path":"2019/05/03/Windows-System-Ubuntu16-04/","text":"Unit 1 : How to install subsystem?*Step1 : Open Microsoft Store and search the key word: “Ubuntu” ，then choose the product: “Ubuntu 16.04 LTS” . * Step2 : Click the button: Get , and wait for it to finish It’s ok! You can launch it , but maybe you can have the problem bellow. Problem1 : WslRegisterDistribution failed with error: 0x8007019e . 1231. OPen the project \"Windows PowerShell(Admin)\"2. Enter the command \"Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux\"3. When the process was completed , reboot your system. Unit 2 ：How to use it?1. Query Ubuntu’s versionEnter the command: 1cat /etc/os-release 2. Update the software source of UbuntuEnter the command as follow: 123cd /etc/aptsudo cp sources.list sources.list.baksudo vi sources.list Delete all content of the file , and enter the content as follow: 12345678910deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse Enter the command to update software: 12sudo apt-get upgrade sudo apt-get update 3. Access the file of Windows SystemYou can access the file in “/mnt” . For example , if accessing the file located in “C:\\Users&quot; , you can enter the command: 1cd /mnt/c/Users/","tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://yoursite.com/tags/Ubuntu/"},{"name":"Tutorial","slug":"Tutorial","permalink":"http://yoursite.com/tags/Tutorial/"}]},{"title":"提醒事项","date":"2019-04-18T19:09:46.000Z","path":"2019/04/19/提醒事项/","text":"每日任务 项目 优先级 坚持天数 背单词 1 100天 跑步 2 50天 未竟事业记录表只记录没有完成每日任务的时候","tags":[{"name":"生活点滴","slug":"生活点滴","permalink":"http://yoursite.com/tags/生活点滴/"}]},{"title":"GitHub设置无密码登录","date":"2019-04-03T12:07:01.000Z","path":"2019/04/03/GitHub设置无密码登录/","text":"GitHub项目的授权方式有两种方式：Https和SSH。 Https可以随意克隆github上的项目，而不管是谁的；而SSH则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。 https url在push的时候是需要验证用户名和密码的；而 SSH在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。 一 安装ssh证书 首先需要检查你电脑是否已经有 SSH key ，在 git Bash 客户端，输入如下代码： 12$ cd ~/.ssh$ ls 1这两个命令就是检查是否已经存在 id_rsa.pub 或 id_dsa.pub 文件，如果文件已经存在，那么则跳过步骤2。 *创建一个 SSH key * 1$ ssh-keygen -t rsa -C \"your_email@example.com\" 123456代码参数含义：-t 指定密钥类型，默认是 rsa ，可以省略。-C 设置注释文字，比如邮箱。-f 指定密钥文件存储文件名。接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码），可以不输入密码，直接按回车。 添加你的 SSH key 到 github上面去 a. 首先你需要拷贝 id_rsa.pub 文件的内容，你可以用编辑器打开文件复制，也可以用git命令复制该文件的内容，如： 1$ clip &lt; ~/.ssh/id_rsa.pub b. 登录你的github账号，从又上角的settings进入，然后点击菜单栏的 SSH key 进入页面添加 SSH key。 c. 点击 Add SSH key 按钮添加一个 SSH key 。把你复制的 SSH key 代码粘贴到 key 所对应的输入框中，记得 SSH key 代码的前后不要留有空格或者回车。title随意。 测试一下该SSH key 1$ ssh -T git@github.com ​ 当你输入以上代码时，会有一段警告代码，如： 123The authenticity of host 'github.com (207.97.227.239)' can't be established.# RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.# Are you sure you want to continue connecting (yes/no)? ​ 输入 yes 既可。 ​ 如果你创建 SSH key 的时候设置了密码，接下来就会提示你输入密码 ​ 注意：输入密码时如果输错一个字就会不正确，使用删除键是无法更正的。 ​ 密码正确后你会看到下面这段话，如： 12Hi username! You've successfully authenticated, but GitHub does not# provide shell access. ​ 如果用户名是正确的,你已经成功设置SSH密钥。 二 已有的项目切换到使用SSH方式连接​ 安装ssh证书，每次push pull 都需要输入git密码，原因是使用了https方式 push。 在terminal里边 输入 git remote -v ，可以看到形如一下的返回结果： 12origin https://cleey@github.com/cleey/phppoem.git (fetch)origin https://cleey@github.com/cleey/phppoem.git (push) 安装以下方式更换成ssh方式的： 123git remote rm origingit remote add origin git@github.com:cleey/phppoem.gitgit push origin","tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"Git 撤销合并操作","date":"2019-01-31T05:01:23.000Z","path":"2019/01/31/Git撤销合并操作/","text":"利用Merge操作合并分支时，可能会出现一些错误，需要撤销合并。这里介绍如何撤销已经上传至github远程仓库的方法 当你使用 git merge 合并两个分支，你将会得到一个commit。执行 git show 之后，会有类似的输出： 123commit 19b7d40d2ebefb4236a8ab630f89e4afca6e9dbeMerge: b0ef24a cca45f9...... 其中，Merge 这一行代表的是合并所用到的两个分支(parents)。举个例子，通常，我们的稳定代码都在 master 分支，而开发过程使用 dev 分支，当开发完成后，再把 dev 分支 merge 进 master 分支： 123a -&gt; b -&gt; c -&gt; f -- g -&gt; h (master) \\ / d -&gt; e (dev) g 是 merge 后得到的代码，g 的两个 parent 分别是 f 和 e。 当你撤销合并，需要添加-m参数来指定撤销合并至哪条分支(parent)。在你合并两个分支并试图撤销时，Git 并不知道你到底需要保留哪一个分支上所做的修改。从 Git 的角度来看，master 分支和 dev 在地位上是完全平等的，只是在 workflow 中，master 被人为约定成了「主分支」。 于是 Git 需要你通过 m 或 mainline 参数来指定「主线」。merge commit 的 parents 一定是在两个不同的线索上，因此可以通过 parent 来表示「主线」。m 参数的值可以是 1 或者 2，对应着 parent 在 merge commit 信息中的顺序。因而，撤销g的合并操作恢复至原主分支f上： 12# g为merge后的索引号git revert -m 1 g 从而变成： 123a -&gt; b -&gt; c -&gt; f -- g -&gt; h -&gt; G -&gt; i (master) \\ / d -&gt; e -&gt; j -&gt; k (dev) 此外，由于撤销操作，则在下一次dev与master合并时，merge操作不会合并d、e两个版本代码。因为git认为已经合并或没有合并的需要。此刻，由于新的要合并的dev是在原有d、e版本上开发的（此刻dev已修复bug），这样合并会出错。 因而，需要先撤销G再合并，G为先前撤销合并恢复至主分支操作生成的编号。 123git checkout mastergit revert Ggit merge dev 参考：https://blog.csdn.net/sndamhming/article/details/56011986","tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"caffe-yolo summary","date":"2019-01-08T03:02:41.000Z","path":"2019/01/08/caffe-yolo-summary/","text":"本博文记录博主对caffe的初步理解以及yolo在caffe上的运行 一、数据处理篇1.1 Dataset转化为LMDB&nbsp;&nbsp;&nbsp;&nbsp;如先前所做的总结，在这里再次强调一下，首先要将数据转化为LMDB或LEVELDB格式，再输入至caffe的数据输入层。而图片转化为LMDB格式时，其形状或维度含义为[heights, weights, channels] 。其代码（位于caffe/src/caffe/util/io.cpp）如下: 123456789101112131415161718192021222324void CVMatToDatum(const cv::Mat&amp; cv_img, Datum* datum) &#123;a CHECK(cv_img.depth() == CV_8U) &lt;&lt; \"Image data type must be unsigned byte\"; datum-&gt;set_channels(cv_img.channels()); datum-&gt;set_height(cv_img.rows); datum-&gt;set_width(cv_img.cols); datum-&gt;clear_data(); datum-&gt;clear_float_data(); datum-&gt;set_encoded(false); int datum_channels = datum-&gt;channels(); int datum_height = datum-&gt;height(); int datum_width = datum-&gt;width(); int datum_size = datum_channels * datum_height * datum_width; std::string buffer(datum_size, ' '); for (int h = 0; h &lt; datum_height; ++h) &#123; const uchar* ptr = cv_img.ptr&lt;uchar&gt;(h); int img_index = 0; for (int w = 0; w &lt; datum_width; ++w) &#123; for (int c = 0; c &lt; datum_channels; ++c) &#123; int datum_index = (c * datum_height + h) * datum_width + w; buffer[datum_index] = static_cast&lt;char&gt;(ptr[img_index++]); &#125; &#125; &#125; datum-&gt;set_data(buffer);&#125; 而label文件对bounding-box的标记也从[Xmin, Ymin, Xmax, Ymax] 转化为[Xmid, Ymid, W, H]，同时，对其进行了归一化操作；并将不同class转为对应的index（按照label_map进行`映射）。其代码（位于caffe/src/caffe/util/io.cpp）如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263void ParseXmlToDatum(const string&amp; annoname, const map&lt;string, int&gt;&amp; label_map, int ori_w, int ori_h, Datum* datum) &#123; ptree pt; read_xml(annoname, pt); int width(0), height(0); try &#123; height = pt.get&lt;int&gt;(\"annotation.size.height\"); width = pt.get&lt;int&gt;(\"annotation.size.width\"); CHECK_EQ(ori_w, width); CHECK_EQ(ori_h, height); &#125; catch (const ptree_error &amp;e) &#123; LOG(WARNING) &lt;&lt; \"When paring \" &lt;&lt; annoname &lt;&lt; \": \" &lt;&lt; e.what(); &#125; datum-&gt;clear_float_data(); BOOST_FOREACH(ptree::value_type &amp;v1, pt.get_child(\"annotation\")) &#123; if (v1.first == \"object\") &#123; ptree object = v1.second; int label(-1); vector&lt;float&gt; box(4, 0); int difficult(0); BOOST_FOREACH(ptree::value_type &amp;v2, object.get_child(\"\")) &#123; ptree pt2 = v2.second; if (v2.first == \"name\") &#123; string name = pt2.data(); // map name to label label = name_to_label(name, label_map); if (label &lt; 0) &#123; LOG(FATAL) &lt;&lt; \"Anno file \" &lt;&lt; annoname &lt;&lt; \" -&gt; unknown name: \" &lt;&lt; name; &#125; &#125; else if (v2.first == \"bndbox\") &#123; int xmin = pt2.get(\"xmin\", 0); int ymin = pt2.get(\"ymin\", 0); int xmax = pt2.get(\"xmax\", 0); int ymax = pt2.get(\"ymax\", 0); LOG_IF(WARNING, xmin &lt; 0 || xmin &gt; ori_w) &lt;&lt; annoname &lt;&lt; \" bounding box exceeds image boundary\"; LOG_IF(WARNING, xmax &lt; 0 || xmax &gt; ori_w) &lt;&lt; annoname &lt;&lt; \" bounding box exceeds image boundary\"; LOG_IF(WARNING, ymin &lt; 0 || ymin &gt; ori_h) &lt;&lt; annoname &lt;&lt; \" bounding box exceeds image boundary\"; LOG_IF(WARNING, ymax &lt; 0 || ymax &gt; ori_h) &lt;&lt; annoname &lt;&lt; \" bounding box exceeds image boundary\"; LOG_IF(WARNING, xmin &gt; xmax) &lt;&lt; annoname &lt;&lt; \" bounding box exceeds image boundary\"; LOG_IF(WARNING, ymin &gt; ymax) &lt;&lt; annoname &lt;&lt; \" bounding box exceeds image boundary\"; box[0] = float(xmin + (xmax - xmin) / 2.) / ori_w; box[1] = float(ymin + (ymax - ymin) / 2.) / ori_h; box[2] = float(xmax - xmin) / ori_w; box[3] = float(ymax - ymin) / ori_h; &#125; else if (v2.first == \"difficult\") &#123; difficult = atoi(pt2.data().c_str()); &#125; &#125; CHECK_GE(label, 0) &lt;&lt; \"label must start at 0\"; datum-&gt;add_float_data(float(label)); datum-&gt;add_float_data(float(difficult)); for (int i = 0; i &lt; 4; ++i) &#123; datum-&gt;add_float_data(box[i]); &#125; &#125; &#125;&#125; 1.2 DataLayeryolo网络训练、测试时所用的DataLayer是BoxDataLayer，该数据输入层是由caffe-yolo原作者编写。这里做一下简单的代码分析： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#ifdef USE_OPENCV#include &lt;opencv2/core/core.hpp&gt;#endif // USE_OPENCV#include &lt;stdint.h&gt;#include &lt;vector&gt;#include \"caffe/data_transformer.hpp\"#include \"caffe/layers/box_data_layer.hpp\"#include \"caffe/util/benchmark.hpp\"namespace caffe &#123;//构造函数，初始化Layer参数，reader_参数; BasePrefetchingDataLayer带预取功能的数据读取层template &lt;typename Dtype&gt;BoxDataLayer&lt;Dtype&gt;::BoxDataLayer(const LayerParameter&amp; param) : BasePrefetchingDataLayer&lt;Dtype&gt;(param), reader_(param) &#123;&#125;//解析函数template &lt;typename Dtype&gt;BoxDataLayer&lt;Dtype&gt;::~BoxDataLayer() &#123; this-&gt;StopInternalThread();&#125;//BoxDataLayer层设置template &lt;typename Dtype&gt;void BoxDataLayer&lt;Dtype&gt;::DataLayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom, const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123; this-&gt;box_label_ = true; const DataParameter param = this-&gt;layer_param_.data_param(); const int batch_size = param.batch_size(); // 读取数据，并使用它来初始化blob的top。 Datum&amp; datum = *(reader_.full().peek()); // 使用data_transformer从datum得到预期的blob形状。 vector&lt;int&gt; top_shape = this-&gt;data_transformer_-&gt;InferBlobShape(datum); this-&gt;transformed_data_.Reshape(top_shape); // Reshape top[0] and prefetch_data according to the batch_size. top_shape[0] = batch_size; top[0]-&gt;Reshape(top_shape); //PREFETCH_COUNT-预取的数据批量数目 for (int i = 0; i &lt; this-&gt;PREFETCH_COUNT; ++i) &#123; this-&gt;prefetch_[i].data_.Reshape(top_shape); &#125; LOG(INFO) &lt;&lt; \"output data size: \" &lt;&lt; top[0]-&gt;num() &lt;&lt; \",\" &lt;&lt; top[0]-&gt;channels() &lt;&lt; \",\" &lt;&lt; top[0]-&gt;height() &lt;&lt; \",\" &lt;&lt; top[0]-&gt;width(); // label if (this-&gt;output_labels_) &#123; if (param.side_size() &gt; 0) &#123; for (int i = 0; i &lt; param.side_size(); ++i) &#123; sides_.push_back(param.side(i)); &#125; &#125; if (sides_.size() == 0) &#123; sides_.push_back(7); &#125; CHECK_EQ(sides_.size(), top.size() - 1) &lt;&lt; \"side num not equal to top size\"; for (int i = 0; i &lt; this-&gt;PREFETCH_COUNT; ++i) &#123; this-&gt;prefetch_[i].multi_label_.clear(); &#125; for (int i = 0; i &lt; sides_.size(); ++i) &#123; vector&lt;int&gt; label_shape(1, batch_size); int label_size = sides_[i] * sides_[i] * (1 + 1 + 1 + 4); label_shape.push_back(label_size); top[i+1]-&gt;Reshape(label_shape); for (int j = 0; j &lt; this-&gt;PREFETCH_COUNT; ++j) &#123; shared_ptr&lt;Blob&lt;Dtype&gt; &gt; tmp_blob; tmp_blob.reset(new Blob&lt;Dtype&gt;(label_shape)); this-&gt;prefetch_[j].multi_label_.push_back(tmp_blob); &#125; &#125; &#125;&#125;// This function is called on prefetch thread// 批量导入数据template&lt;typename Dtype&gt;void BoxDataLayer&lt;Dtype&gt;::load_batch(Batch&lt;Dtype&gt;* batch) &#123; CPUTimer batch_timer; batch_timer.Start(); double read_time = 0; double trans_time = 0; CPUTimer timer; CHECK(batch-&gt;data_.count()); CHECK(this-&gt;transformed_data_.count()); // Reshape according to the first datum of each batch // on single input batches allows for inputs of varying dimension. const int batch_size = this-&gt;layer_param_.data_param().batch_size(); Datum&amp; datum = *(reader_.full().peek()); // Use data_transformer to infer the expected blob shape from datum. vector&lt;int&gt; top_shape = this-&gt;data_transformer_-&gt;InferBlobShape(datum); this-&gt;transformed_data_.Reshape(top_shape); // Reshape batch according to the batch_size. top_shape[0] = batch_size; batch-&gt;data_.Reshape(top_shape); Dtype* top_data = batch-&gt;data_.mutable_cpu_data(); vector&lt;Dtype*&gt; top_label; if (this-&gt;output_labels_) &#123; for (int i = 0; i &lt; sides_.size(); ++i) &#123; top_label.push_back(batch-&gt;multi_label_[i]-&gt;mutable_cpu_data()); &#125; &#125; for (int item_id = 0; item_id &lt; batch_size; ++item_id) &#123; timer.Start(); // get a datum Datum&amp; datum = *(reader_.full().pop(\"Waiting for data\")); read_time += timer.MicroSeconds(); timer.Start(); // Apply data transformations (mirror, scale, crop...) int offset = batch-&gt;data_.offset(item_id); vector&lt;BoxLabel&gt; box_labels; this-&gt;transformed_data_.set_cpu_data(top_data + offset); if (this-&gt;output_labels_) &#123; // rand sample a patch, adjust box labels this-&gt;data_transformer_-&gt;Transform(datum, &amp;(this-&gt;transformed_data_), &amp;box_labels); // transform label for (int i = 0; i &lt; sides_.size(); ++i) &#123; int label_offset = batch-&gt;multi_label_[i]-&gt;offset(item_id); int count = batch-&gt;multi_label_[i]-&gt;count(1); transform_label(count, top_label[i] + label_offset, box_labels, sides_[i]); &#125; &#125; else &#123; this-&gt;data_transformer_-&gt;Transform(datum, &amp;(this-&gt;transformed_data_)); &#125; trans_time += timer.MicroSeconds(); reader_.free().push(const_cast&lt;Datum*&gt;(&amp;datum)); &#125; timer.Stop(); batch_timer.Stop(); DLOG(INFO) &lt;&lt; \"Prefetch batch: \" &lt;&lt; batch_timer.MilliSeconds() &lt;&lt; \" ms.\"; DLOG(INFO) &lt;&lt; \" Read time: \" &lt;&lt; read_time / 1000 &lt;&lt; \" ms.\"; DLOG(INFO) &lt;&lt; \"Transform time: \" &lt;&lt; trans_time / 1000 &lt;&lt; \" ms.\";&#125;//生成通过数据转化器生成的数据对应的labeltemplate&lt;typename Dtype&gt;void BoxDataLayer&lt;Dtype&gt;::transform_label(int count, Dtype* top_label, const vector&lt;BoxLabel&gt;&amp; box_labels, int side) &#123; int locations = pow(side, 2); CHECK_EQ(count, locations * 7) &lt;&lt; \"side and count not match\"; // difficult caffe_set(locations, Dtype(0), top_label); // isobj caffe_set(locations, Dtype(0), top_label + locations); // class label caffe_set(locations, Dtype(-1), top_label + locations * 2); // box caffe_set(locations*4, Dtype(0), top_label + locations * 3); for (int i = 0; i &lt; box_labels.size(); ++i) &#123; float difficult = box_labels[i].difficult_; if (difficult != 0. &amp;&amp; difficult != 1.) &#123; LOG(WARNING) &lt;&lt; \"Difficult must be 0 or 1\"; &#125; float class_label = box_labels[i].class_label_; CHECK_GE(class_label, 0) &lt;&lt; \"class_label must &gt;= 0\"; float x = box_labels[i].box_[0]; float y = box_labels[i].box_[1]; // LOG(INFO) &lt;&lt; \"x: \" &lt;&lt; x &lt;&lt; \" y: \" &lt;&lt; y; int x_index = floor(x * side); int y_index = floor(y * side); x_index = std::min(x_index, side - 1); y_index = std::min(y_index, side - 1); int dif_index = side * y_index + x_index; int obj_index = locations + dif_index; int class_index = locations * 2 + dif_index; int cor_index = locations * 3 + dif_index * 4; top_label[dif_index] = difficult; top_label[obj_index] = 1; // LOG(INFO) &lt;&lt; \"dif_index: \" &lt;&lt; dif_index &lt;&lt; \" class_label: \" &lt;&lt; class_label; top_label[class_index] = class_label; for (int j = 0; j &lt; 4; ++j) &#123; top_label[cor_index + j] = box_labels[i].box_[j]; &#125; &#125;&#125;//实例化BoxDataLayer、BoxDataINSTANTIATE_CLASS(BoxDataLayer);REGISTER_LAYER_CLASS(BoxData);&#125; // namespace caffe 1.3 Input与预处理&nbsp;&nbsp;&nbsp;&nbsp;在进行图像预处理时，可以使用去均值操作，其目的是使得像素值更接近（0,0,0）原点，从而加快收敛速度。如果在数据层加入去均值操作，预测时也需要进行去均值操作。如无，则无需！其方法如下： 1234//(104,117,123)为imagenet均值，可自行根据数据集生成均值。mean_value: 104mean_value: 117mean_value: 123 &nbsp;&nbsp;&nbsp;&nbsp;同时，图像预处理的目的之一是保证输入数据与网络输入层所要求的shape保持一致。通过opencv.imread(img_path)函数读取的图片为（heights, weights, channels）。而deploy.prototxt中的input层为（channels, heights, weights）。因此，在进行预测时需要对输入图片进行预处理。 12345im = cv2.imread(im_path)im = cv2.resize(im, (160, 160))im = np.require(im.transpose((2, 0, 1)), dtype=np.float32)#在训练时没有进行去均值，因此在预测时也没有进行去均值。#im -= mean 而转化为graph文件后，其网络输入层为（heights, weights, channels），附件为转为graph文件后的网络结构图：点击查看或下载因此，无需对输入图片进行预处理： 12im = cv2.imread(input_image_path)im = cv2.resize(im, (160, 160)) 二、caffe简介2.1 Project结构&nbsp;&nbsp;&nbsp;&nbsp;在caffe架构下搭建网络是通过prototxt文件描述的，以此建立统一的参数管理机制。在prototxt文件中，不仅包含基本的网络结构，还包含Loss层（Train时需要）、输入数据的路径和结构（Train与Test时需要）、输入数据size/ shape（如1601603,Deploy时需要）。因此，不同于keras，caffe的网络结构文件需要多个。&nbsp;&nbsp;&nbsp;&nbsp;首先，solver.prototxt（即求解器）的主要功能是设置超参数，确定优化方式；其次， train.prototxt与test.prototxt的主要功能是搭建网络结构，设置结构参数用于训练与测试，确定loss层；最后，deploy.prototxt的主要功能是搭建最基础的网络结构用于预测。 2.2 网络结构deploy.prototxt内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396name: \"tiny-yolo\"input: \"data\"input_shape &#123; dim: 1 dim: 3 dim: 160 dim: 160&#125;layer &#123; name: \"conv1\" type: \"Convolution\" bottom: \"data\" top: \"conv1\" convolution_param &#123; num_output: 16 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn1\" type: \"BatchNorm\" bottom: \"conv1\" top: \"bn1\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale1\" type: \"Scale\" bottom: \"bn1\" top: \"scale1\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu1\" type: \"ReLU\" bottom: \"scale1\" top: \"scale1\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"pool1\" type: \"Pooling\" bottom: \"scale1\" top: \"pool1\" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: \"conv2\" type: \"Convolution\" bottom: \"pool1\" top: \"conv2\" convolution_param &#123; num_output: 32 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn2\" type: \"BatchNorm\" bottom: \"conv2\" top: \"bn2\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale2\" type: \"Scale\" bottom: \"bn2\" top: \"scale2\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu2\" type: \"ReLU\" bottom: \"scale2\" top: \"scale2\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"pool2\" type: \"Pooling\" bottom: \"scale2\" top: \"pool2\" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: \"conv3\" type: \"Convolution\" bottom: \"pool2\" top: \"conv3\" convolution_param &#123; num_output: 64 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn3\" type: \"BatchNorm\" bottom: \"conv3\" top: \"bn3\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale3\" type: \"Scale\" bottom: \"bn3\" top: \"scale3\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu3\" type: \"ReLU\" bottom: \"scale3\" top: \"scale3\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"pool3\" type: \"Pooling\" bottom: \"scale3\" top: \"pool3\" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: \"conv4\" type: \"Convolution\" bottom: \"pool3\" top: \"conv4\" convolution_param &#123; num_output: 128 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn4\" type: \"BatchNorm\" bottom: \"conv4\" top: \"bn4\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale4\" type: \"Scale\" bottom: \"bn4\" top: \"scale4\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu4\" type: \"ReLU\" bottom: \"scale4\" top: \"scale4\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"pool4\" type: \"Pooling\" bottom: \"scale4\" top: \"pool4\" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: \"conv5\" type: \"Convolution\" bottom: \"pool4\" top: \"conv5\" convolution_param &#123; num_output: 256 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn5\" type: \"BatchNorm\" bottom: \"conv5\" top: \"bn5\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale5\" type: \"Scale\" bottom: \"bn5\" top: \"scale5\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu5\" type: \"ReLU\" bottom: \"scale5\" top: \"scale5\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"pool5\" type: \"Pooling\" bottom: \"scale5\" top: \"pool5\" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: \"conv6\" type: \"Convolution\" bottom: \"pool5\" top: \"conv6\" convolution_param &#123; num_output: 512 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn6\" type: \"BatchNorm\" bottom: \"conv6\" top: \"bn6\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale6\" type: \"Scale\" bottom: \"bn6\" top: \"scale6\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu6\" type: \"ReLU\" bottom: \"scale6\" top: \"scale6\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"pool6\" type: \"Pooling\" bottom: \"scale6\" top: \"pool6\" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layer &#123; name: \"conv7\" type: \"Convolution\" bottom: \"pool6\" top: \"conv7\" convolution_param &#123; num_output: 1024 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn7\" type: \"BatchNorm\" bottom: \"conv7\" top: \"bn7\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale7\" type: \"Scale\" bottom: \"bn7\" top: \"scale7\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu7\" type: \"ReLU\" bottom: \"scale7\" top: \"scale7\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"conv8\" type: \"Convolution\" bottom: \"scale7\" top: \"conv8\" convolution_param &#123; num_output: 256 kernel_size: 3 pad: 1 bias_term: false &#125;&#125;layer &#123; name: \"bn8\" type: \"BatchNorm\" bottom: \"conv8\" top: \"bn8\" batch_norm_param &#123; use_global_stats: true &#125;&#125;layer &#123; name: \"scale8\" type: \"Scale\" bottom: \"bn8\" top: \"scale8\" scale_param &#123; bias_term: true &#125;&#125;layer &#123; name: \"relu8\" type: \"ReLU\" bottom: \"scale8\" top: \"scale8\" relu_param &#123; negative_slope: 0.1 &#125;&#125;layer &#123; name: \"fc9\" type: \"InnerProduct\" bottom: \"scale8\" top: \"fc9\" inner_product_param &#123; num_output: 300 &#125;&#125; 三、Tiny YOLO&nbsp;&nbsp;&nbsp;&nbsp;Tiny-YOLO是YOLO算法的简单实现。相比于YOLO算法，它的网络结构更浅，仅有9层。除此外，其理论基础与YOLO并无二致。 3.1 Yolo Innovation&nbsp;&nbsp;&nbsp;&nbsp;YOLO算法首创的实现了端到端的目标检测算法，是速度惊人、准确度较好的one-stage算法。YOLO算法将整张图片划分为SXS的grid，采用一次性预测所有格子所含目标的bounding-box、confidence以及P(object)和P(class|object)。&nbsp;&nbsp;&nbsp;&nbsp;网络的输出结果为一个向量，size为：S * S * (B * 5 +C)。其中，S为划分网格数，B为每个网格负责目标个数，C为类别个数。其含义为：每个网格会对应B个边界框，边界框的宽高范围为全图，而中心点落于该网格；每个边界框对应一个置信度值，代表该处是否有物体及定位准确度（即Confidence = P(object) * IOU(predict-box, ground-truth)。）；每个网格对应C个概率，分别代表每个class出现的概率。&nbsp;&nbsp;&nbsp;&nbsp;而YOLO是如何实现对输入图像的分格呢？&nbsp;&nbsp;&nbsp;&nbsp;原作者巧妙地在最后预测层设置了S * S * (B * 5 +C)个神经元（该层为全连接层，在yolo2中该层为1*1的卷积层），通过训练将对应不同网格的ground-truth收敛到对应的网格的输出中。 3.2 Loss&nbsp;&nbsp;&nbsp;&nbsp;损失函数的设计目标就是让坐标（x,y,w,h），confidence，classification 这个三个方面达到很好的平衡。简单的全部采用了sum-squared error loss来做这件事会有以下不足：首先，(num_side*4)维的localization error和(num_classes)维的classification error每一个维度产生的代价同等重要，这显然是不合理的。其次，如果一些栅格中没有object（一幅图中这种栅格很多），那么就会将这些栅格中的bounding box的confidence置为0，相比于较少的有object的栅格，这些不包含物体的栅格对梯度更新的贡献会远大于包含物体的栅格对梯度更新的贡献，这会导致网络不稳定甚至发散。&nbsp;&nbsp;&nbsp;&nbsp;因此，YOLO采取了更有效的Loss函数。将loss函数分为3部分：第一，坐标预测是否准确(图片中书写有误，xy值与groundtruth应相减不因相加)；第二，有无object预测是否准确；第三，类别预测。&nbsp;&nbsp;&nbsp;&nbsp;更重视8维的坐标预测，给这些损失前面赋予更大的loss weight, 记为 λcoord ,在pascal VOC训练中取5。对没有object的bbox的confidence loss，赋予小的loss weight，记为 λnoobj ，在pascal VOC训练中取0.5。有object的bbox的confidence loss 和类别的loss 的loss weight正常取1。&nbsp;&nbsp;&nbsp;&nbsp;对不同大小的bbox预测中，相比于大bbox预测偏一点，小box预测偏相同的尺寸对IOU的影响更大。而sum-square error loss中对同样的偏移loss是一样。为了缓和这个问题，作者用了一个巧妙的办法，就是将box的width和height取平方根代替原本的height和width。 如下：small bbox的横轴值较小，发生偏移时，反应到y轴上的loss（下图绿色）比big box(下图红色)要大。 四、Train &amp;&amp; Test4.1 Optimization本项目测试过SGD、momentum 、Adam。最终，Adam效果最佳。 4.2 solver.prototxt(Adam)123456789101112131415161718192021net: \"x_train.prototxt\"test_iter: 3000test_interval: 32000test_initialization: falsedisplay: 20average_loss: 100lr_policy: \"multifixed\"stagelr: 0.001stagelr: 0.0001stagelr: 0.00001stagelr: 0.000001stageiter: 520stageiter: 16000stageiter: 24000stageiter: 32000max_iter: 32000momentum: 0.9weight_decay: 0.0005snapshot: 2000snapshot_prefix: \"./models/x_yolo\"solver_mode: GPU 4.3 train.prototxt点击下载 五、Predict123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#!/usr/bin/env pythonimport numpy as npimport cv2import osimport syssys.path.insert(0, '/home/mc/Desktop/caffe/caffe/python/')import caffe############################global variable set start############################num_classes = 2num_anchors = 2side = 5net_proto = \"./x_deploy.prototxt\"model_path = \"./models/x_yolo_iter_32000.caffemodel\"im_path = '/home/mc/Desktop/caffe-yolo/data/yolo/VOCdevkit/VOC2018/JPEGImages/826.jpg'############################global variable set end..#############################environment setscaffe.set_device(0)caffe.set_mode_gpu()#nms filterdef nms(boxes, thresh): x1 = boxes[:, 0] - boxes[:, 2] / 2. y1 = boxes[:, 1] - boxes[:, 3] / 2. x2 = boxes[:, 0] + boxes[:, 2] / 2. y2 = boxes[:, 1] + boxes[:, 3] / 2. scores = boxes[:, 4] areas = (x2 - x1 + 1) * (y2 - y1 + 1) order = scores.argsort()[::-1] keep = [] while order.size &gt; 0: i = order[0] keep.append(i) ix1 = np.maximum(x1[i], x1[order[1:]]) iy1 = np.maximum(y1[i], y1[order[1:]]) ix2 = np.minimum(x2[i], x2[order[1:]]) iy2 = np.minimum(y2[i], y2[order[1:]]) w = np.maximum(0.0, ix2-ix1+1) h = np.maximum(0.0, iy2-iy1+1) inter = w * h ovr = inter / (areas[i] + areas[order[1:]] - inter) inds = np.where(ovr &lt;= thresh)[0] order = order[inds + 1] return boxes[np.require(keep), :]#parse resultdef parse_result(out_put): global num_classes global num_anchors global side locations = side ** 2 boxes = np.zeros((num_anchors * locations, 6), dtype=np.float32) for i in range(locations): tmp_scores = out_put[i:num_classes*locations:locations] max_class_ind = np.argsort(tmp_scores)[-1] max_prob = np.max(tmp_scores) obj_index = num_classes * locations + i obj_scores = max_prob * out_put[obj_index:(obj_index+num_anchors*locations):locations] coor_index = (num_classes + num_anchors) * locations + i for j in range(num_anchors): boxes[i*num_anchors+j][5] = max_class_ind boxes[i*num_anchors+j][4] = obj_scores[j] box_index = coor_index + j * 4 * locations boxes[i*num_anchors+j][0] = (i % side + out_put[box_index + 0 * locations]) / float(side) boxes[i*num_anchors+j][1] = (i / side + out_put[box_index + 1 * locations]) / float(side) boxes[i*num_anchors+j][2] = out_put[box_index + 2 * locations] ** 2 boxes[i*num_anchors+j][3] = out_put[box_index + 3 * locations] ** 2 return nms(boxes, 0.5)#show or write result_picturedef show_boxes(im_path, boxes, sthresh=0.5, hthresh=1, show=0): print (boxes.shape) im = cv2.imread(im_path) ori_w = im.shape[1] ori_h = im.shape[0] for box in boxes: if box[4] &lt; sthresh: continue if box[4] &gt; hthresh: continue print (box) box = box[:4] x1 = max(0, int((box[0] - box[2] / 2.) * ori_w)) y1 = max(0, int((box[1] - box[3] / 2.) * ori_h)) x2 = min(ori_w - 1, int((box[0] + box[2] / 2.) * ori_w)) y2 = min(ori_h - 1, int((box[1] + box[3] / 2.) * ori_h)) cv2.rectangle(im, (x1, y1), (x2, y2), (0, 255, 255), 2) name = os.path.split(im_path)[1].split('.')[0] if show: cv2.imshow(\"out\", im) else: cv2.imwrite(\"adam-out-n\"+name+'.jpg', im)# predictdef predict(model, im_path): # image pre-processing im = cv2.imread(im_path) im = cv2.resize(im, (160, 160)) im = np.require(im.transpose((2, 0, 1)), dtype=np.float32) # forward process... model.blobs['data'].data[...] = im out_blobs = model.forward() ''' The structure of out_put is: [n*n*class1,n*n*class2,...,n*n*class(i),n*n*score1,n*n*score2,n*n*(x,y,w,h)1,n*n*(x,y,w,h)2] p.s. n is side ''' reg_out = out_blobs[\"fc9\"] boxes = parse_result(reg_out[0]) show_boxes(im_path, boxes, 0.2)if __name__==\"__main__\": global net_proto global model_path global im_path # load net with model model = caffe.Net(net_proto, model_path, caffe.TEST) predict(model, im_path)","tags":[{"name":"caffe","slug":"caffe","permalink":"http://yoursite.com/tags/caffe/"},{"name":"cv","slug":"cv","permalink":"http://yoursite.com/tags/cv/"}]},{"title":"安装教程：Ubuntu16.04+CUDA9.0+CUDNN7.1+caffe(gpu)+opencv","date":"2018-12-27T17:45:17.000Z","path":"2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/","text":"本教程适用于CUDA9.0+CUDNN7.1+OPENCV(3.4.0) 一、依赖包安装 在Ubuntu的Terminal中输入： 1234sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compilersudo apt-get install --no-install-recommends libboost-all-devsudo apt-get install libopenblas-dev liblapack-dev libatlas-base-devsudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev 二、驱动安装(Nvidia 384.X版本的驱动)方式一在Terminal输入： 123456sudo apt-get update sudo add-apt-repository ppa:graphics-drivers/ppa sudo apt-get update sudo apt-get install nvidia-384 sudo apt-get install mesa-common-dev sudo apt-getinstall freeglut3-dev 方式二直接在Ubuntu中的System Settings–&gt;Software&amp;Updates中的additional drivers：驱动安装成功的标志： 三、CUDA9.0安装请通过官网下载CUDA安装文件（.run文件)，运行文件命令如下： 12# 先CD至.run文件的文件夹，再运行该命令sudo sh cuda_9.0.176_384.81_linux.run 先按q直接跳过阅读协议，然后accept，后面的除了Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?这样的选n,其它的有y选y，或者直接回车默认检查一下环境变量 1gedit ~/.bashr 末尾添加 123#cudaexport LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64/:$LD_LIBRARY_PATHexport PATH=/usr/local/cuda-9.0/bin:$PATH 然后激活 1source ~/.bashrc 检验安装是否完整： 四、CUDNN7.1安装请通过官网下载CUDNN安装文件（.tgz文件)，直接在Terminal中cd至所在文件夹，运行以下命令： 12345tar -zxvf cudnn-9.0-linux-x64-v7.1.tgz sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ -d sudo chmod a+r /usr/local/cuda/include/cudnn.h sudo chmod a+r /usr/local/cuda/lib64/libcudnn* 检验是否安装完整： 五、Opencv源码编译安装将下载好的opencv源码（.zip文件）解压缩至home文件夹下，然后在Terminal中输入： 123456cd ~/opencv-3.4.1mkdir build cd build cmake -D CMAKE_BUILD_TYPE=Release .. sudo make -j8sudo make install 安装完后检验: 六、Caffe安装此处我直接安装到home目录，执行： 12cd ~ git clone https://github.com/BVLC/caffe.git #开始clone 等待下载结束，下载结束后在你的home路径下会存在，caffe文件夹。接下来进入caffe并开始配置caffe，配置如下: 12sudo cp Makefile.config.example Makefile.configsudo gedit Makefile.config #或者sudo vim Makefile.config 修改Makefile.config内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849将：#USE_CUDNN := 1修改为： USE_CUDNN := 1将：#OPENCV_VERSION := 3 修改为： OPENCV_VERSION := 3将：#WITH_PYTHON_LAYER := 1修改为WITH_PYTHON_LAYER := 1将：INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/includeLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib修改为：INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serialLIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial将# CUDA architecture setting: going with all of them.# For CUDA &amp;lt; 6.0, comment the *_50 through *_61 lines for compatibility.# For CUDA &amp;lt; 8.0, comment the *_60 and *_61 lines for compatibility.# For CUDA &amp;gt;= 9.0, comment the *_20 and *_21 lines for compatibility.CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \\ -gencode arch=compute_20,code=sm_21 \\ -gencode arch=compute_30,code=sm_30 \\ -gencode arch=compute_35,code=sm_35 \\ -gencode arch=compute_50,code=sm_50 \\ -gencode arch=compute_52,code=sm_52 \\ -gencode arch=compute_60,code=sm_60 \\ -gencode arch=compute_61,code=sm_61 \\ -gencode arch=compute_61,code=compute_61改为：# CUDA architecture setting: going with all of them.# For CUDA &amp;lt; 6.0, comment the *_50 through *_61 lines for compatibility.# For CUDA &amp;lt; 8.0, comment the *_60 and *_61 lines for compatibility.# For CUDA &amp;gt;= 9.0, comment the *_20 and *_21 lines for compatibility.CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \\ -gencode arch=compute_35,code=sm_35 \\ -gencode arch=compute_50,code=sm_50 \\ -gencode arch=compute_52,code=sm_52 \\ -gencode arch=compute_60,code=sm_60 \\ -gencode arch=compute_61,code=sm_61 \\ -gencode arch=compute_61,code=compute_61 修改Makefile文件： 123456789将：NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS)替换为：NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)将：LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5改为：LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial 配置完好之后开始编译： 123456cd caffesudo make cleansudo make all #或者make all -j4(代表4核，或者j8)sudo make testsudo make runtest #或者sudo make runtest -j8sudo make pycaffe 检验是否安装完整：所有的test中，如果编译不报错，则说明安装完整。","tags":[{"name":"caffe","slug":"caffe","permalink":"http://yoursite.com/tags/caffe/"}]}]