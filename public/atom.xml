<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mwessj</title>
  
  <subtitle>青春不是年华，而是心境</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-18T19:23:34.086Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>翁嘉进(Mwessj Weng)</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>提醒事项</title>
    <link href="http://yoursite.com/2019/04/19/%E6%8F%90%E9%86%92%E4%BA%8B%E9%A1%B9/"/>
    <id>http://yoursite.com/2019/04/19/提醒事项/</id>
    <published>2019-04-18T19:09:46.000Z</published>
    <updated>2019-04-18T19:23:34.086Z</updated>
    
    <content type="html"><![CDATA[<h1 id="每日任务"><a href="#每日任务" class="headerlink" title="每日任务"></a>每日任务</h1><table><thead><tr><th style="text-align:center">项目</th><th style="text-align:center">优先级</th><th style="text-align:center">坚持天数</th></tr></thead><tbody><tr><td style="text-align:center">背单词</td><td style="text-align:center">1</td><td style="text-align:center">100天</td></tr><tr><td style="text-align:center">跑步</td><td style="text-align:center">2</td><td style="text-align:center">50天</td></tr></tbody></table><h1 id="未竟事业记录表"><a href="#未竟事业记录表" class="headerlink" title="未竟事业记录表"></a>未竟事业记录表</h1><p>只记录没有完成每日任务的时候</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;每日任务&quot;&gt;&lt;a href=&quot;#每日任务&quot; class=&quot;headerlink&quot; title=&quot;每日任务&quot;&gt;&lt;/a&gt;每日任务&lt;/h1&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&quot;text-align:center&quot;&gt;项目&lt;/th&gt;
&lt;th st
      
    
    </summary>
    
    
      <category term="生活点滴" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>落星</title>
    <link href="http://yoursite.com/2019/04/19/%E8%90%BD%E6%98%9F/"/>
    <id>http://yoursite.com/2019/04/19/落星/</id>
    <published>2019-04-18T18:53:28.000Z</published>
    <updated>2019-04-18T18:59:17.517Z</updated>
    
    <content type="html"><![CDATA[<p>去不该去的地方，做不该做的事情，这也是勇气啊！             ——《侠肝义胆沈剑心》（2019.04.19）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;去不该去的地方，做不该做的事情，这也是勇气啊！             ——《侠肝义胆沈剑心》（2019.04.19）&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="生活点滴" scheme="http://yoursite.com/tags/%E7%94%9F%E6%B4%BB%E7%82%B9%E6%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>GitHub设置无密码登录</title>
    <link href="http://yoursite.com/2019/04/03/GitHub%E8%AE%BE%E7%BD%AE%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95/"/>
    <id>http://yoursite.com/2019/04/03/GitHub设置无密码登录/</id>
    <published>2019-04-03T12:07:01.000Z</published>
    <updated>2019-04-11T13:28:38.711Z</updated>
    
    <content type="html"><![CDATA[<p><strong>GitHub项目的授权方式有两种方式：Https和SSH。</strong></p><p>Https可以随意克隆github上的项目，而不管是谁的；而SSH则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。</p><p>https url在push的时候是需要验证用户名和密码的；而 SSH在push的时候，是不需要输入用户名的，如果配置SSH key的时候设置了密码，则需要输入密码的，否则直接是不需要输入密码的。</p><h2 id="一-安装ssh证书"><a href="#一-安装ssh证书" class="headerlink" title="一 安装ssh证书"></a>一 安装ssh证书</h2><hr><ol><li><strong>首先需要检查你电脑是否已经有 SSH key ，在 git Bash 客户端，输入如下代码：</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/.ssh</span><br><span class="line">$ ls</span><br></pre></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这两个命令就是检查是否已经存在 id_rsa<span class="selector-class">.pub</span> 或 id_dsa<span class="selector-class">.pub</span> 文件，如果文件已经存在，那么则跳过步骤<span class="number">2</span>。</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>创建一个 SSH key </strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C <span class="string">"your_email@example.com"</span></span><br></pre></td></tr></table></figure><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">代码参数含义：</span><br><span class="line"><span class="deletion">-t 指定密钥类型，默认是 rsa ，可以省略。</span></span><br><span class="line"><span class="deletion">-C 设置注释文字，比如邮箱。</span></span><br><span class="line"><span class="deletion">-f 指定密钥文件存储文件名。</span></span><br><span class="line"></span><br><span class="line">接着又会提示你输入两次密码（该密码是你push文件的时候要输入的密码，而不是github管理者的密码），可以不输入密码，直接按回车。</span><br></pre></td></tr></table></figure><ol start="3"><li><p><strong>添加你的 SSH key 到 github上面去</strong></p><p>a. 首先你需要拷贝 id_rsa.pub 文件的内容，你可以用编辑器打开文件复制，也可以用git命令复制该文件的内容，如：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ clip &lt; ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><pre><code>b. 登录你的github账号，从又上角的settings进入，然后点击菜单栏的 SSH key 进入页面添加 SSH key。c. 点击 Add SSH key 按钮添加一个 SSH key 。把你复制的 SSH key 代码粘贴到 key 所对应的输入框中，记得 SSH key 代码的前后不要留有空格或者回车。title随意。</code></pre><ol start="4"><li><strong>测试一下该SSH key</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh -T git@github.com</span><br></pre></td></tr></table></figure><p>​    当你输入以上代码时，会有一段警告代码，如：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The authenticity <span class="keyword">of</span> host 'github.com (<span class="number">207.97</span><span class="number">.227</span><span class="number">.239</span>)' can't be established.</span><br><span class="line"><span class="comment"># RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.</span></span><br><span class="line"><span class="comment"># Are you sure you want to continue connecting (yes/no)?</span></span><br></pre></td></tr></table></figure><p>​    输入 yes 既可。</p><p>​    如果你创建 SSH key 的时候设置了密码，接下来就会提示你输入密码</p><p>​    注意：输入密码时如果输错一个字就会不正确，使用删除键是无法更正的。</p><p>​    密码正确后你会看到下面这段话，如：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hi username! You've successfully authenticated, <span class="keyword">but</span> GitHub <span class="keyword">does</span> <span class="keyword">not</span></span><br><span class="line"><span class="comment"># provide shell access.</span></span><br></pre></td></tr></table></figure><p>​    如果用户名是正确的,你已经成功设置SSH密钥。</p><hr><h2 id="二-已有的项目切换到使用SSH方式连接"><a href="#二-已有的项目切换到使用SSH方式连接" class="headerlink" title="二 已有的项目切换到使用SSH方式连接"></a>二 已有的项目切换到使用SSH方式连接</h2><p>​    安装ssh证书，每次push pull 都需要输入git密码，原因是使用了https方式 push。</p><ol><li>在terminal里边 输入  git remote -v ，可以看到形如一下的返回结果：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">origin  https://cleey@github.com/cleey/phppoem.git (fetch)</span><br><span class="line">origin  https://cleey@github.com/cleey/phppoem.git (push)</span><br></pre></td></tr></table></figure><ol start="2"><li>安装以下方式更换成ssh方式的：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git remote rm origin</span><br><span class="line">git remote add origin git@github.com:cleey/phppoem.git</span><br><span class="line">git push origin</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;GitHub项目的授权方式有两种方式：Https和SSH。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Https可以随意克隆github上的项目，而不管是谁的；而SSH则是你必须是你要克隆的项目的拥有者或管理员，且需要先添加 SSH key ，否则无法克隆。&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Git 撤销合并操作</title>
    <link href="http://yoursite.com/2019/01/31/Git%E6%92%A4%E9%94%80%E5%90%88%E5%B9%B6%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2019/01/31/Git撤销合并操作/</id>
    <published>2019-01-31T05:01:23.000Z</published>
    <updated>2019-01-31T06:26:11.656Z</updated>
    
    <content type="html"><![CDATA[<p><strong>利用Merge操作合并分支时，可能会出现一些错误，需要撤销合并。这里介绍如何撤销已经上传至github远程仓库的方法</strong></p><p>当你使用 git merge 合并两个分支，你将会得到一个commit。执行 git show 之后，会有类似的输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">commit 19b7d40d2ebefb4236a8ab630f89e4afca6e9dbe</span><br><span class="line">Merge: b0ef24a cca45f9</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>其中，Merge 这一行代表的是合并所用到的两个分支(parents)。举个例子，通常，我们的稳定代码都在 master 分支，而开发过程使用 dev 分支，当开发完成后，再把 dev 分支 merge 进 master 分支：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a -&gt; b -&gt; c -&gt; f -- g -&gt; h (master)</span><br><span class="line">           \      /</span><br><span class="line">            d -&gt; e  (dev)</span><br></pre></td></tr></table></figure><p>g 是 merge 后得到的代码，g 的两个 parent 分别是 f 和 e。</p><p>当你撤销合并，需要添加-m参数来指定撤销合并至哪条分支(parent)。<br>在你合并两个分支并试图撤销时，Git 并不知道你到底需要保留哪一个分支上所做的修改。从 Git 的角度来看，master 分支和 dev 在地位上是完全平等的，只是在 workflow 中，master 被人为约定成了「主分支」。</p><p>于是 Git 需要你通过 m 或 mainline 参数来指定「主线」。merge commit 的 parents 一定是在两个不同的线索上，因此可以通过 parent 来表示「主线」。m 参数的值可以是 1 或者 2，对应着 parent 在 merge commit 信息中的顺序。<br>因而，撤销g的合并操作恢复至原主分支f上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># g为merge后的索引号</span></span><br><span class="line">git revert -m 1 g</span><br></pre></td></tr></table></figure></p><p>从而变成：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a -&gt; b -&gt; c -&gt; f -- g -&gt; h -&gt; G -&gt; i (master)</span><br><span class="line">           \      /</span><br><span class="line">            d -&gt; e -&gt; j -&gt; k (dev)</span><br></pre></td></tr></table></figure></p><p>此外，由于撤销操作，则在下一次dev与master合并时，merge操作不会合并d、e两个版本代码。因为git认为已经合并或没有合并的需要。此刻，由于新的要合并的dev是在原有d、e版本上开发的（此刻dev已修复bug），这样合并会出错。</p><p>因而，需要先撤销G再合并，G为先前撤销合并恢复至主分支操作生成的编号。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git checkout master</span><br><span class="line">git revert G</span><br><span class="line">git merge dev</span><br></pre></td></tr></table></figure></p><p>参考：<a href="https://blog.csdn.net/sndamhming/article/details/56011986" target="_blank" rel="noopener">https://blog.csdn.net/sndamhming/article/details/56011986</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;利用Merge操作合并分支时，可能会出现一些错误，需要撤销合并。这里介绍如何撤销已经上传至github远程仓库的方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当你使用 git merge 合并两个分支，你将会得到一个commit。执行 git show 之后，会有类
      
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>caffe-yolo summary</title>
    <link href="http://yoursite.com/2019/01/08/caffe-yolo-summary/"/>
    <id>http://yoursite.com/2019/01/08/caffe-yolo-summary/</id>
    <published>2019-01-08T03:02:41.000Z</published>
    <updated>2019-01-08T04:30:36.131Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本博文记录博主对caffe的初步理解以及yolo在caffe上的运行</strong></p><h2 id="一、数据处理篇"><a href="#一、数据处理篇" class="headerlink" title="一、数据处理篇"></a>一、数据处理篇</h2><h3 id="1-1-Dataset转化为LMDB"><a href="#1-1-Dataset转化为LMDB" class="headerlink" title="1.1 Dataset转化为LMDB"></a>1.1 Dataset转化为LMDB</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;如先前所做的总结，在这里再次强调一下，首先要将数据转化为LMDB或LEVELDB格式，再输入至caffe的数据输入层。而图片转化为LMDB格式时，其形状或维度含义为[heights, weights, channels] 。其代码（位于caffe/src/caffe/util/io.cpp）如下:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">void CVMatToDatum(const cv::Mat&amp; cv_img, Datum* datum) &#123;a  CHECK(cv_img.depth() == CV_8U) &lt;&lt; "Image data type must be unsigned byte";</span><br><span class="line">  datum-&gt;set_channels(cv_img.channels());</span><br><span class="line">  datum-&gt;set_height(cv_img.rows);</span><br><span class="line">  datum-&gt;set_width(cv_img.cols);</span><br><span class="line">  datum-&gt;clear_data();</span><br><span class="line">  datum-&gt;clear_float_data();</span><br><span class="line">  datum-&gt;set_encoded(<span class="literal">false</span>);</span><br><span class="line">  <span class="keyword">int</span> datum_channels = datum-&gt;channels();</span><br><span class="line">  <span class="keyword">int</span> datum_height = datum-&gt;height();</span><br><span class="line">  <span class="keyword">int</span> datum_width = datum-&gt;width();</span><br><span class="line">  <span class="keyword">int</span> datum_size = datum_channels * datum_height * datum_width;</span><br><span class="line">  <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">buffer</span><span class="params">(datum_size, <span class="string">' '</span>)</span></span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> h = <span class="number">0</span>; h &lt; datum_height; ++h) &#123;</span><br><span class="line">    <span class="keyword">const</span> uchar* ptr = cv_img.ptr&lt;uchar&gt;(h);</span><br><span class="line">    <span class="keyword">int</span> img_index = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> w = <span class="number">0</span>; w &lt; datum_width; ++w) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> c = <span class="number">0</span>; c &lt; datum_channels; ++c) &#123;</span><br><span class="line">        <span class="keyword">int</span> datum_index = (c * datum_height + h) * datum_width + w;</span><br><span class="line">        buffer[datum_index] = <span class="keyword">static_cast</span>&lt;<span class="keyword">char</span>&gt;(ptr[img_index++]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  datum-&gt;set_data(buffer);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>而label文件对bounding-box的标记也从[Xmin, Ymin, Xmax, Ymax] 转化为[Xmid, Ymid, W, H]，同时，对其进行了归一化操作；并将不同class转为对应的index（按照label_map进行`映射）。其代码（位于caffe/src/caffe/util/io.cpp）如下:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ParseXmlToDatum</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; annoname, <span class="keyword">const</span> <span class="built_in">map</span>&lt;<span class="built_in">string</span>, <span class="keyword">int</span>&gt;&amp; label_map,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> ori_w, <span class="keyword">int</span> ori_h, Datum* datum)</span> </span>&#123;</span><br><span class="line">  ptree pt;</span><br><span class="line">  read_xml(annoname, pt);</span><br><span class="line">  int width(0), height(0);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    height = pt.get&lt;<span class="keyword">int</span>&gt;(<span class="string">"annotation.size.height"</span>);</span><br><span class="line">    width = pt.get&lt;<span class="keyword">int</span>&gt;(<span class="string">"annotation.size.width"</span>);</span><br><span class="line">    CHECK_EQ(ori_w, width);</span><br><span class="line">    CHECK_EQ(ori_h, height);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (<span class="keyword">const</span> ptree_error &amp;e) &#123;</span><br><span class="line">    LOG(WARNING) &lt;&lt; <span class="string">"When paring "</span> &lt;&lt; annoname &lt;&lt; <span class="string">": "</span> &lt;&lt; e.what();</span><br><span class="line">  &#125;</span><br><span class="line">  datum-&gt;clear_float_data();</span><br><span class="line">  BOOST_FOREACH(ptree::value_type &amp;v1, pt.get_child(<span class="string">"annotation"</span>)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (v1.first == <span class="string">"object"</span>) &#123;</span><br><span class="line">      ptree object = v1.second;</span><br><span class="line">      <span class="function"><span class="keyword">int</span> <span class="title">label</span><span class="params">(<span class="number">-1</span>)</span></span>;</span><br><span class="line">      <span class="built_in">vector</span>&lt;<span class="keyword">float</span>&gt; box(<span class="number">4</span>, <span class="number">0</span>);</span><br><span class="line">      <span class="function"><span class="keyword">int</span> <span class="title">difficult</span><span class="params">(<span class="number">0</span>)</span></span>;</span><br><span class="line">      BOOST_FOREACH(ptree::value_type &amp;v2, object.get_child(<span class="string">""</span>)) &#123;</span><br><span class="line">        ptree pt2 = v2.second;</span><br><span class="line">        <span class="keyword">if</span> (v2.first == <span class="string">"name"</span>) &#123;</span><br><span class="line">          <span class="built_in">string</span> name = pt2.data();</span><br><span class="line">          <span class="comment">// map name to label</span></span><br><span class="line">          label = name_to_label(name, label_map);</span><br><span class="line">          <span class="keyword">if</span> (label &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            LOG(FATAL) &lt;&lt; <span class="string">"Anno file "</span> &lt;&lt; annoname &lt;&lt; <span class="string">" -&gt; unknown name: "</span> &lt;&lt; name;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v2.first == <span class="string">"bndbox"</span>) &#123;</span><br><span class="line">          <span class="keyword">int</span> xmin = pt2.get(<span class="string">"xmin"</span>, <span class="number">0</span>);</span><br><span class="line">          <span class="keyword">int</span> ymin = pt2.get(<span class="string">"ymin"</span>, <span class="number">0</span>);</span><br><span class="line">          <span class="keyword">int</span> xmax = pt2.get(<span class="string">"xmax"</span>, <span class="number">0</span>);</span><br><span class="line">          <span class="keyword">int</span> ymax = pt2.get(<span class="string">"ymax"</span>, <span class="number">0</span>);</span><br><span class="line">          LOG_IF(WARNING, xmin &lt; <span class="number">0</span> || xmin &gt; ori_w) &lt;&lt; annoname &lt;&lt;</span><br><span class="line">              <span class="string">" bounding box exceeds image boundary"</span>;</span><br><span class="line">          LOG_IF(WARNING, xmax &lt; <span class="number">0</span> || xmax &gt; ori_w) &lt;&lt; annoname &lt;&lt;</span><br><span class="line">              <span class="string">" bounding box exceeds image boundary"</span>;</span><br><span class="line">          LOG_IF(WARNING, ymin &lt; <span class="number">0</span> || ymin &gt; ori_h) &lt;&lt; annoname &lt;&lt;</span><br><span class="line">              <span class="string">" bounding box exceeds image boundary"</span>;</span><br><span class="line">          LOG_IF(WARNING, ymax &lt; <span class="number">0</span> || ymax &gt; ori_h) &lt;&lt; annoname &lt;&lt;</span><br><span class="line">              <span class="string">" bounding box exceeds image boundary"</span>;</span><br><span class="line">          LOG_IF(WARNING, xmin &gt; xmax) &lt;&lt; annoname &lt;&lt;</span><br><span class="line">              <span class="string">" bounding box exceeds image boundary"</span>;</span><br><span class="line">          LOG_IF(WARNING, ymin &gt; ymax) &lt;&lt; annoname &lt;&lt;</span><br><span class="line">              <span class="string">" bounding box exceeds image boundary"</span>;</span><br><span class="line">          box[<span class="number">0</span>] = <span class="keyword">float</span>(xmin + (xmax - xmin) / <span class="number">2.</span>) / ori_w;</span><br><span class="line">          box[<span class="number">1</span>] = <span class="keyword">float</span>(ymin + (ymax - ymin) / <span class="number">2.</span>) / ori_h;</span><br><span class="line">          box[<span class="number">2</span>] = <span class="keyword">float</span>(xmax - xmin) / ori_w;</span><br><span class="line">          box[<span class="number">3</span>] = <span class="keyword">float</span>(ymax - ymin) / ori_h;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (v2.first == <span class="string">"difficult"</span>) &#123;</span><br><span class="line">          difficult = atoi(pt2.data().c_str());</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      CHECK_GE(label, <span class="number">0</span>) &lt;&lt; <span class="string">"label must start at 0"</span>;</span><br><span class="line">      datum-&gt;add_float_data(<span class="keyword">float</span>(label));</span><br><span class="line">      datum-&gt;add_float_data(<span class="keyword">float</span>(difficult));</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; ++i) &#123;</span><br><span class="line">        datum-&gt;add_float_data(box[i]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="1-2-DataLayer"><a href="#1-2-DataLayer" class="headerlink" title="1.2 DataLayer"></a>1.2 DataLayer</h3><p>yolo网络训练、测试时所用的DataLayer是BoxDataLayer，该数据输入层是由caffe-yolo原作者编写。这里做一下简单的代码分析：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> USE_OPENCV</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// USE_OPENCV</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/data_transformer.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/box_data_layer.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/util/benchmark.hpp"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"><span class="comment">//构造函数，初始化Layer参数，reader_参数; BasePrefetchingDataLayer带预取功能的数据读取层</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">BoxDataLayer&lt;Dtype&gt;::BoxDataLayer(<span class="keyword">const</span> LayerParameter&amp; param)</span><br><span class="line">  : BasePrefetchingDataLayer&lt;Dtype&gt;(param),</span><br><span class="line">    reader_(param) &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//解析函数</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line">BoxDataLayer&lt;Dtype&gt;::~BoxDataLayer() &#123;</span><br><span class="line">  <span class="keyword">this</span>-&gt;StopInternalThread();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//BoxDataLayer层设置</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> BoxDataLayer&lt;Dtype&gt;::DataLayerSetUp(<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span><br><span class="line">  <span class="keyword">this</span>-&gt;box_label_ = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">const</span> DataParameter param = <span class="keyword">this</span>-&gt;layer_param_.data_param();</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> batch_size = param.batch_size();</span><br><span class="line">  <span class="comment">// 读取数据，并使用它来初始化blob的top。</span></span><br><span class="line">  Datum&amp; datum = *(reader_.full().peek());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用data_transformer从datum得到预期的blob形状。</span></span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; top_shape = <span class="keyword">this</span>-&gt;data_transformer_-&gt;InferBlobShape(datum);</span><br><span class="line">  <span class="keyword">this</span>-&gt;transformed_data_.Reshape(top_shape);</span><br><span class="line">  <span class="comment">// Reshape top[0] and prefetch_data according to the batch_size.</span></span><br><span class="line">  top_shape[<span class="number">0</span>] = batch_size;</span><br><span class="line">  top[<span class="number">0</span>]-&gt;Reshape(top_shape);</span><br><span class="line">  <span class="comment">//PREFETCH_COUNT-预取的数据批量数目</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;PREFETCH_COUNT; ++i) &#123;</span><br><span class="line">    <span class="keyword">this</span>-&gt;prefetch_[i].data_.Reshape(top_shape);</span><br><span class="line">  &#125;</span><br><span class="line">  LOG(INFO) &lt;&lt; <span class="string">"output data size: "</span> &lt;&lt; top[<span class="number">0</span>]-&gt;num() &lt;&lt; <span class="string">","</span></span><br><span class="line">      &lt;&lt; top[<span class="number">0</span>]-&gt;channels() &lt;&lt; <span class="string">","</span> &lt;&lt; top[<span class="number">0</span>]-&gt;height() &lt;&lt; <span class="string">","</span></span><br><span class="line">      &lt;&lt; top[<span class="number">0</span>]-&gt;width();</span><br><span class="line">  <span class="comment">// label</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;output_labels_) &#123;</span><br><span class="line">    <span class="keyword">if</span> (param.side_size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; param.side_size(); ++i) &#123;</span><br><span class="line">        sides_.push_back(param.side(i));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (sides_.size() == <span class="number">0</span>) &#123;</span><br><span class="line">      sides_.push_back(<span class="number">7</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    CHECK_EQ(sides_.size(), top.size() - <span class="number">1</span>) &lt;&lt;</span><br><span class="line">      <span class="string">"side num not equal to top size"</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;PREFETCH_COUNT; ++i) &#123;</span><br><span class="line">      <span class="keyword">this</span>-&gt;prefetch_[i].multi_label_.clear();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sides_.size(); ++i) &#123;</span><br><span class="line">      <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; label_shape(<span class="number">1</span>, batch_size);</span><br><span class="line">      <span class="keyword">int</span> label_size = sides_[i] * sides_[i] * (<span class="number">1</span> + <span class="number">1</span> + <span class="number">1</span> + <span class="number">4</span>);</span><br><span class="line">      label_shape.push_back(label_size);</span><br><span class="line">      top[i+<span class="number">1</span>]-&gt;Reshape(label_shape);</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="keyword">this</span>-&gt;PREFETCH_COUNT; ++j) &#123;</span><br><span class="line">        <span class="built_in">shared_ptr</span>&lt;Blob&lt;Dtype&gt; &gt; tmp_blob;</span><br><span class="line">        tmp_blob.reset(<span class="keyword">new</span> Blob&lt;Dtype&gt;(label_shape));</span><br><span class="line">        <span class="keyword">this</span>-&gt;prefetch_[j].multi_label_.push_back(tmp_blob);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// This function is called on prefetch thread</span></span><br><span class="line"><span class="comment">// 批量导入数据</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> BoxDataLayer&lt;Dtype&gt;::load_batch(Batch&lt;Dtype&gt;* batch) &#123;</span><br><span class="line">  CPUTimer batch_timer;</span><br><span class="line">  batch_timer.Start();</span><br><span class="line">  <span class="keyword">double</span> read_time = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">double</span> trans_time = <span class="number">0</span>;</span><br><span class="line">  CPUTimer timer;</span><br><span class="line">  CHECK(batch-&gt;data_.count());</span><br><span class="line">  CHECK(<span class="keyword">this</span>-&gt;transformed_data_.count());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Reshape according to the first datum of each batch</span></span><br><span class="line">  <span class="comment">// on single input batches allows for inputs of varying dimension.</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> batch_size = <span class="keyword">this</span>-&gt;layer_param_.data_param().batch_size();</span><br><span class="line">  Datum&amp; datum = *(reader_.full().peek());</span><br><span class="line">  <span class="comment">// Use data_transformer to infer the expected blob shape from datum.</span></span><br><span class="line">  <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; top_shape = <span class="keyword">this</span>-&gt;data_transformer_-&gt;InferBlobShape(datum);</span><br><span class="line">  <span class="keyword">this</span>-&gt;transformed_data_.Reshape(top_shape);</span><br><span class="line">  <span class="comment">// Reshape batch according to the batch_size.</span></span><br><span class="line">  top_shape[<span class="number">0</span>] = batch_size;</span><br><span class="line">  batch-&gt;data_.Reshape(top_shape);</span><br><span class="line"></span><br><span class="line">  Dtype* top_data = batch-&gt;data_.mutable_cpu_data();</span><br><span class="line">  <span class="built_in">vector</span>&lt;Dtype*&gt; top_label;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;output_labels_) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sides_.size(); ++i) &#123;</span><br><span class="line">      top_label.push_back(batch-&gt;multi_label_[i]-&gt;mutable_cpu_data());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> item_id = <span class="number">0</span>; item_id &lt; batch_size; ++item_id) &#123;</span><br><span class="line">    timer.Start();</span><br><span class="line">    <span class="comment">// get a datum</span></span><br><span class="line">    Datum&amp; datum = *(reader_.full().pop(<span class="string">"Waiting for data"</span>));</span><br><span class="line">    read_time += timer.MicroSeconds();</span><br><span class="line">    timer.Start();</span><br><span class="line">    <span class="comment">// Apply data transformations (mirror, scale, crop...)</span></span><br><span class="line">    <span class="keyword">int</span> offset = batch-&gt;data_.offset(item_id);</span><br><span class="line">    <span class="built_in">vector</span>&lt;BoxLabel&gt; box_labels;</span><br><span class="line">    <span class="keyword">this</span>-&gt;transformed_data_.set_cpu_data(top_data + offset);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;output_labels_) &#123;</span><br><span class="line">      <span class="comment">// rand sample a patch, adjust box labels</span></span><br><span class="line">      <span class="keyword">this</span>-&gt;data_transformer_-&gt;Transform(datum, &amp;(<span class="keyword">this</span>-&gt;transformed_data_), &amp;box_labels);</span><br><span class="line">      <span class="comment">// transform label</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; sides_.size(); ++i) &#123;</span><br><span class="line">        <span class="keyword">int</span> label_offset = batch-&gt;multi_label_[i]-&gt;offset(item_id);</span><br><span class="line">        <span class="keyword">int</span> count  = batch-&gt;multi_label_[i]-&gt;count(<span class="number">1</span>);</span><br><span class="line">        transform_label(count, top_label[i] + label_offset, box_labels, sides_[i]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">this</span>-&gt;data_transformer_-&gt;Transform(datum, &amp;(<span class="keyword">this</span>-&gt;transformed_data_));</span><br><span class="line">    &#125;</span><br><span class="line">    trans_time += timer.MicroSeconds();</span><br><span class="line"></span><br><span class="line">    reader_.<span class="built_in">free</span>().push(<span class="keyword">const_cast</span>&lt;Datum*&gt;(&amp;datum));</span><br><span class="line">  &#125;</span><br><span class="line">  timer.Stop();</span><br><span class="line">  batch_timer.Stop();</span><br><span class="line">  DLOG(INFO) &lt;&lt; <span class="string">"Prefetch batch: "</span> &lt;&lt; batch_timer.MilliSeconds() &lt;&lt; <span class="string">" ms."</span>;</span><br><span class="line">  DLOG(INFO) &lt;&lt; <span class="string">"     Read time: "</span> &lt;&lt; read_time / <span class="number">1000</span> &lt;&lt; <span class="string">" ms."</span>;</span><br><span class="line">  DLOG(INFO) &lt;&lt; <span class="string">"Transform time: "</span> &lt;&lt; trans_time / <span class="number">1000</span> &lt;&lt; <span class="string">" ms."</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//生成通过数据转化器生成的数据对应的label</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> BoxDataLayer&lt;Dtype&gt;::transform_label(<span class="keyword">int</span> count, Dtype* top_label,</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">vector</span>&lt;BoxLabel&gt;&amp; box_labels, <span class="keyword">int</span> side) &#123;</span><br><span class="line">  <span class="keyword">int</span> locations = <span class="built_in">pow</span>(side, <span class="number">2</span>);</span><br><span class="line">  CHECK_EQ(count, locations * <span class="number">7</span>) &lt;&lt;</span><br><span class="line">    <span class="string">"side and count not match"</span>;</span><br><span class="line">  <span class="comment">// difficult</span></span><br><span class="line">  caffe_set(locations, Dtype(<span class="number">0</span>), top_label);</span><br><span class="line">  <span class="comment">// isobj</span></span><br><span class="line">  caffe_set(locations, Dtype(<span class="number">0</span>), top_label + locations);</span><br><span class="line">  <span class="comment">// class label</span></span><br><span class="line">  caffe_set(locations, Dtype(<span class="number">-1</span>), top_label + locations * <span class="number">2</span>);</span><br><span class="line">  <span class="comment">// box</span></span><br><span class="line">  caffe_set(locations*<span class="number">4</span>, Dtype(<span class="number">0</span>), top_label + locations * <span class="number">3</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; box_labels.size(); ++i) &#123;</span><br><span class="line">    <span class="keyword">float</span> difficult = box_labels[i].difficult_;</span><br><span class="line">    <span class="keyword">if</span> (difficult != <span class="number">0.</span> &amp;&amp; difficult != <span class="number">1.</span>) &#123;</span><br><span class="line">      LOG(WARNING) &lt;&lt; <span class="string">"Difficult must be 0 or 1"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">float</span> class_label = box_labels[i].class_label_;</span><br><span class="line">    CHECK_GE(class_label, <span class="number">0</span>) &lt;&lt; <span class="string">"class_label must &gt;= 0"</span>;</span><br><span class="line">    <span class="keyword">float</span> x = box_labels[i].box_[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">float</span> y = box_labels[i].box_[<span class="number">1</span>];</span><br><span class="line">    <span class="comment">// LOG(INFO) &lt;&lt; "x: " &lt;&lt; x &lt;&lt; " y: " &lt;&lt; y;</span></span><br><span class="line">    <span class="keyword">int</span> x_index = <span class="built_in">floor</span>(x * side);</span><br><span class="line">    <span class="keyword">int</span> y_index = <span class="built_in">floor</span>(y * side);</span><br><span class="line">    x_index = <span class="built_in">std</span>::min(x_index, side - <span class="number">1</span>);</span><br><span class="line">    y_index = <span class="built_in">std</span>::min(y_index, side - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> dif_index = side * y_index + x_index;</span><br><span class="line">    <span class="keyword">int</span> obj_index = locations + dif_index;</span><br><span class="line">    <span class="keyword">int</span> class_index = locations * <span class="number">2</span> + dif_index;</span><br><span class="line">    <span class="keyword">int</span> cor_index = locations * <span class="number">3</span> + dif_index * <span class="number">4</span>;</span><br><span class="line">    top_label[dif_index] = difficult;</span><br><span class="line">    top_label[obj_index] = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// LOG(INFO) &lt;&lt; "dif_index: " &lt;&lt; dif_index &lt;&lt; " class_label: " &lt;&lt; class_label;</span></span><br><span class="line">    top_label[class_index] = class_label;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; ++j) &#123;</span><br><span class="line">      top_label[cor_index + j] = box_labels[i].box_[j];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//实例化BoxDataLayer、BoxData</span></span><br><span class="line">INSTANTIATE_CLASS(BoxDataLayer);</span><br><span class="line">REGISTER_LAYER_CLASS(BoxData);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure><h3 id="1-3-Input与预处理"><a href="#1-3-Input与预处理" class="headerlink" title="1.3 Input与预处理"></a>1.3 Input与预处理</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;在进行图像预处理时，可以使用去均值操作，其目的是使得像素值更接近（0,0,0）原点，从而加快收敛速度。如果在数据层加入去均值操作，预测时也需要进行去均值操作。如无，则无需！其方法如下：<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//(104,117,123)为imagenet均值，可自行根据数据集生成均值。</span></span><br><span class="line">mean<span class="number">_</span><span class="keyword">value</span>: <span class="number">104</span></span><br><span class="line">mean<span class="number">_</span><span class="keyword">value</span>: <span class="number">117</span></span><br><span class="line">mean<span class="number">_</span><span class="keyword">value</span>: <span class="number">123</span></span><br></pre></td></tr></table></figure></p><p>&nbsp;&nbsp;&nbsp;&nbsp;同时，图像预处理的目的之一是保证输入数据与网络输入层所要求的shape保持一致。通过opencv.imread(img_path)函数读取的图片为（heights, weights, channels）。而deploy.prototxt中的input层为（channels, heights, weights）。因此，在进行预测时需要对输入图片进行预处理。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">im = cv2.imread(im_path)</span><br><span class="line">im = cv2.resize(im, (<span class="number">160</span>, <span class="number">160</span>))</span><br><span class="line">im = np.require(im.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)), dtype=np.float32)</span><br><span class="line"><span class="comment">#在训练时没有进行去均值，因此在预测时也没有进行去均值。</span></span><br><span class="line"><span class="comment">#im -= mean</span></span><br></pre></td></tr></table></figure></p><p>而转化为graph文件后，其网络输入层为（heights, weights, channels），附件为转为graph文件后的网络结构图：<br><a href="output.gv.svg">点击查看或下载</a><br>因此，无需对输入图片进行预处理：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">im = cv2.imread(input_image_path)</span><br><span class="line">im = cv2.resize(im, (160, 160))</span><br></pre></td></tr></table></figure></p><h2 id="二、caffe简介"><a href="#二、caffe简介" class="headerlink" title="二、caffe简介"></a>二、caffe简介</h2><h3 id="2-1-Project结构"><a href="#2-1-Project结构" class="headerlink" title="2.1 Project结构"></a>2.1 Project结构</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;在caffe架构下搭建网络是通过prototxt文件描述的，以此建立统一的参数管理机制。在prototxt文件中，不仅包含基本的网络结构，还包含Loss层（Train时需要）、输入数据的路径和结构（Train与Test时需要）、输入数据size/ shape（如160<em>160</em>3,Deploy时需要）。因此，不同于keras，caffe的网络结构文件需要多个。<br>&nbsp;&nbsp;&nbsp;&nbsp;首先，solver.prototxt（即求解器）的主要功能是设置超参数，确定优化方式；其次， train.prototxt与test.prototxt的主要功能是搭建网络结构，设置结构参数用于训练与测试，确定loss层；最后，deploy.prototxt的主要功能是搭建最基础的网络结构用于预测。<br><img src="/2019/01/08/caffe-yolo-summary/1.png" alt="效果图"></p><h3 id="2-2-网络结构"><a href="#2-2-网络结构" class="headerlink" title="2.2 网络结构"></a>2.2 网络结构</h3><p>deploy.prototxt内容如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"tiny-yolo"</span></span><br><span class="line">input: <span class="string">"data"</span></span><br><span class="line">input_shape &#123;</span><br><span class="line">  dim: 1</span><br><span class="line">  dim: 3</span><br><span class="line">  dim: 160</span><br><span class="line">  dim: 160</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"data"</span></span><br><span class="line">  top: <span class="string">"conv1"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 16</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv1"</span></span><br><span class="line">  top: <span class="string">"bn1"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn1"</span></span><br><span class="line">  top: <span class="string">"scale1"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale1"</span></span><br><span class="line">  top: <span class="string">"scale1"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool1"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"scale1"</span></span><br><span class="line">  top: <span class="string">"pool1"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool1"</span></span><br><span class="line">  top: <span class="string">"conv2"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 32</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv2"</span></span><br><span class="line">  top: <span class="string">"bn2"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn2"</span></span><br><span class="line">  top: <span class="string">"scale2"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale2"</span></span><br><span class="line">  top: <span class="string">"scale2"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool2"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"scale2"</span></span><br><span class="line">  top: <span class="string">"pool2"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv3"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool2"</span></span><br><span class="line">  top: <span class="string">"conv3"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 64</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn3"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv3"</span></span><br><span class="line">  top: <span class="string">"bn3"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale3"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn3"</span></span><br><span class="line">  top: <span class="string">"scale3"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu3"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale3"</span></span><br><span class="line">  top: <span class="string">"scale3"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool3"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"scale3"</span></span><br><span class="line">  top: <span class="string">"pool3"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv4"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool3"</span></span><br><span class="line">  top: <span class="string">"conv4"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 128</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn4"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv4"</span></span><br><span class="line">  top: <span class="string">"bn4"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale4"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn4"</span></span><br><span class="line">  top: <span class="string">"scale4"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu4"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale4"</span></span><br><span class="line">  top: <span class="string">"scale4"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool4"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"scale4"</span></span><br><span class="line">  top: <span class="string">"pool4"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv5"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool4"</span></span><br><span class="line">  top: <span class="string">"conv5"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 256</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn5"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv5"</span></span><br><span class="line">  top: <span class="string">"bn5"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale5"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn5"</span></span><br><span class="line">  top: <span class="string">"scale5"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu5"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale5"</span></span><br><span class="line">  top: <span class="string">"scale5"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool5"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"scale5"</span></span><br><span class="line">  top: <span class="string">"pool5"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv6"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool5"</span></span><br><span class="line">  top: <span class="string">"conv6"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 512</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn6"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv6"</span></span><br><span class="line">  top: <span class="string">"bn6"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale6"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn6"</span></span><br><span class="line">  top: <span class="string">"scale6"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu6"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale6"</span></span><br><span class="line">  top: <span class="string">"scale6"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"pool6"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Pooling"</span></span><br><span class="line">  bottom: <span class="string">"scale6"</span></span><br><span class="line">  top: <span class="string">"pool6"</span></span><br><span class="line">  pooling_param &#123;</span><br><span class="line">    pool: MAX</span><br><span class="line">    kernel_size: 2</span><br><span class="line">    stride: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv7"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"pool6"</span></span><br><span class="line">  top: <span class="string">"conv7"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 1024</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn7"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv7"</span></span><br><span class="line">  top: <span class="string">"bn7"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale7"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn7"</span></span><br><span class="line">  top: <span class="string">"scale7"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu7"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale7"</span></span><br><span class="line">  top: <span class="string">"scale7"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"conv8"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Convolution"</span></span><br><span class="line">  bottom: <span class="string">"scale7"</span></span><br><span class="line">  top: <span class="string">"conv8"</span></span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: 256</span><br><span class="line">    kernel_size: 3</span><br><span class="line">    pad: 1</span><br><span class="line">    bias_term: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"bn8"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"BatchNorm"</span></span><br><span class="line">  bottom: <span class="string">"conv8"</span></span><br><span class="line">  top: <span class="string">"bn8"</span></span><br><span class="line">  batch_norm_param &#123;</span><br><span class="line">    use_global_stats: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"scale8"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"Scale"</span></span><br><span class="line">  bottom: <span class="string">"bn8"</span></span><br><span class="line">  top: <span class="string">"scale8"</span></span><br><span class="line">  scale_param &#123;</span><br><span class="line">    bias_term: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"relu8"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"ReLU"</span></span><br><span class="line">  bottom: <span class="string">"scale8"</span></span><br><span class="line">  top: <span class="string">"scale8"</span></span><br><span class="line">  relu_param &#123;</span><br><span class="line">    negative_slope: 0.1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">"fc9"</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">"InnerProduct"</span></span><br><span class="line">  bottom: <span class="string">"scale8"</span></span><br><span class="line">  top: <span class="string">"fc9"</span></span><br><span class="line">  inner_product_param &#123;</span><br><span class="line">    num_output: 300</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="三、Tiny-YOLO"><a href="#三、Tiny-YOLO" class="headerlink" title="三、Tiny YOLO"></a>三、Tiny YOLO</h2><p><strong>&nbsp;&nbsp;&nbsp;&nbsp;Tiny-YOLO是YOLO算法的简单实现。相比于YOLO算法，它的网络结构更浅，仅有9层。除此外，其理论基础与YOLO并无二致。</strong></p><h3 id="3-1-Yolo-Innovation"><a href="#3-1-Yolo-Innovation" class="headerlink" title="3.1 Yolo Innovation"></a>3.1 Yolo Innovation</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;YOLO算法首创的实现了端到端的目标检测算法，是速度惊人、准确度较好的one-stage算法。YOLO算法将整张图片划分为SXS的grid，采用一次性预测所有格子所含目标的bounding-box、confidence以及P(object)和P(class|object)。<br>&nbsp;&nbsp;&nbsp;&nbsp;网络的输出结果为一个向量，size为：S <em> S </em> (B <em> 5 +C)。其中，S为划分网格数，B为每个网格负责目标个数，C为类别个数。其含义为：每个网格会对应B个边界框，边界框的宽高范围为全图，而中心点落于该网格；每个边界框对应一个置信度值，代表该处是否有物体及定位准确度（即Confidence = P(object) </em> IOU(predict-box, ground-truth)。）；每个网格对应C个概率，分别代表每个class出现的概率。<br>&nbsp;&nbsp;&nbsp;&nbsp;而YOLO是如何实现对输入图像的分格呢？<br>&nbsp;&nbsp;&nbsp;&nbsp;原作者巧妙地在最后预测层设置了S <em> S </em> (B <em> 5 +C)个神经元（该层为全连接层，在yolo2中该层为1</em>1的卷积层），通过训练将对应不同网格的ground-truth收敛到对应的网格的输出中。</p><h3 id="3-2-Loss"><a href="#3-2-Loss" class="headerlink" title="3.2 Loss"></a>3.2 Loss</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;损失函数的设计目标就是让坐标（x,y,w,h），confidence，classification 这个三个方面达到很好的平衡。简单的全部采用了sum-squared error loss来做这件事会有以下不足：<br>首先，(num_side*4)维的localization error和(num_classes)维的classification error每一个维度产生的代价同等重要，这显然是不合理的。<br>其次，如果一些栅格中没有object（一幅图中这种栅格很多），那么就会将这些栅格中的bounding box的confidence置为0，相比于较少的有object的栅格，这些不包含物体的栅格对梯度更新的贡献会远大于包含物体的栅格对梯度更新的贡献，这会导致网络不稳定甚至发散。<br>&nbsp;&nbsp;&nbsp;&nbsp;因此，YOLO采取了更有效的Loss函数。将loss函数分为3部分：第一，坐标预测是否准确(图片中书写有误，xy值与groundtruth应相减不因相加)；第二，有无object预测是否准确；第三，类别预测。<br><img src="/2019/01/08/caffe-yolo-summary/2.png" alt="效果图"><br><img src="/2019/01/08/caffe-yolo-summary/3.png" alt="效果图"><br>&nbsp;&nbsp;&nbsp;&nbsp;更重视8维的坐标预测，给这些损失前面赋予更大的loss weight, 记为 λcoord ,在pascal VOC训练中取5。对没有object的bbox的confidence loss，赋予小的loss weight，记为 λnoobj ，在pascal VOC训练中取0.5。有object的bbox的confidence loss 和类别的loss 的loss weight正常取1。<br>&nbsp;&nbsp;&nbsp;&nbsp;对不同大小的bbox预测中，相比于大bbox预测偏一点，小box预测偏相同的尺寸对IOU的影响更大。而sum-square error loss中对同样的偏移loss是一样。为了缓和这个问题，作者用了一个巧妙的办法，就是将box的width和height取平方根代替原本的height和width。 如下：small bbox的横轴值较小，发生偏移时，反应到y轴上的loss（下图绿色）比big box(下图红色)要大。<br><img src="/2019/01/08/caffe-yolo-summary/4.png" alt="效果图"></p><h2 id="四、Train-amp-amp-Test"><a href="#四、Train-amp-amp-Test" class="headerlink" title="四、Train &amp;&amp; Test"></a>四、Train &amp;&amp; Test</h2><h3 id="4-1-Optimization"><a href="#4-1-Optimization" class="headerlink" title="4.1 Optimization"></a>4.1 Optimization</h3><p>本项目测试过SGD、momentum 、Adam。最终，Adam效果最佳。</p><h3 id="4-2-solver-prototxt-Adam"><a href="#4-2-solver-prototxt-Adam" class="headerlink" title="4.2 solver.prototxt(Adam)"></a>4.2 solver.prototxt(Adam)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">net: <span class="string">"x_train.prototxt"</span></span><br><span class="line">test_iter: 3000</span><br><span class="line">test_interval: 32000</span><br><span class="line">test_initialization: <span class="literal">false</span></span><br><span class="line">display: 20</span><br><span class="line">average_loss: 100</span><br><span class="line">lr_policy: <span class="string">"multifixed"</span></span><br><span class="line">stagelr: 0.001</span><br><span class="line">stagelr: 0.0001</span><br><span class="line">stagelr: 0.00001</span><br><span class="line">stagelr: 0.000001</span><br><span class="line">stageiter: 520</span><br><span class="line">stageiter: 16000</span><br><span class="line">stageiter: 24000</span><br><span class="line">stageiter: 32000</span><br><span class="line">max_iter: 32000</span><br><span class="line">momentum: 0.9</span><br><span class="line">weight_decay: 0.0005</span><br><span class="line">snapshot: 2000</span><br><span class="line">snapshot_prefix: <span class="string">"./models/x_yolo"</span></span><br><span class="line">solver_mode: GPU</span><br></pre></td></tr></table></figure><h3 id="4-3-train-prototxt"><a href="#4-3-train-prototxt" class="headerlink" title="4.3 train.prototxt"></a>4.3 train.prototxt</h3><p><a href="train.prototxt">点击下载</a></p><h2 id="五、Predict"><a href="#五、Predict" class="headerlink" title="五、Predict"></a>五、Predict</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import sys</span><br><span class="line">sys.path.insert(0, <span class="string">'/home/mc/Desktop/caffe/caffe/python/'</span>)</span><br><span class="line"></span><br><span class="line">import caffe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">###########################</span></span><br><span class="line"><span class="comment">#global variable set start#</span></span><br><span class="line"><span class="comment">###########################</span></span><br><span class="line"></span><br><span class="line">num_classes = 2</span><br><span class="line">num_anchors = 2</span><br><span class="line">side = 5</span><br><span class="line"></span><br><span class="line">net_proto = <span class="string">"./x_deploy.prototxt"</span></span><br><span class="line">model_path = <span class="string">"./models/x_yolo_iter_32000.caffemodel"</span></span><br><span class="line">im_path = <span class="string">'/home/mc/Desktop/caffe-yolo/data/yolo/VOCdevkit/VOC2018/JPEGImages/826.jpg'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###########################</span></span><br><span class="line"><span class="comment">#global variable set end..#</span></span><br><span class="line"><span class="comment">###########################</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#environment sets</span></span><br><span class="line">caffe.set_device(0)</span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"></span><br><span class="line"><span class="comment">#nms filter</span></span><br><span class="line">def nms(boxes, thresh):</span><br><span class="line">    x1 = boxes[:, 0] - boxes[:, 2] / 2.</span><br><span class="line">    y1 = boxes[:, 1] - boxes[:, 3] / 2.</span><br><span class="line">    x2 = boxes[:, 0] + boxes[:, 2] / 2.</span><br><span class="line">    y2 = boxes[:, 1] + boxes[:, 3] / 2.</span><br><span class="line">    scores = boxes[:, 4]</span><br><span class="line">    areas = (x2 - x1 + 1) * (y2 - y1 + 1)</span><br><span class="line">    order = scores.argsort()[::-1]</span><br><span class="line">    keep = []</span><br><span class="line">    <span class="keyword">while</span> order.size &gt; 0:</span><br><span class="line">        i = order[0]</span><br><span class="line">        keep.append(i)</span><br><span class="line">        ix1 = np.maximum(x1[i], x1[order[1:]])</span><br><span class="line">        iy1 = np.maximum(y1[i], y1[order[1:]])</span><br><span class="line">        ix2 = np.minimum(x2[i], x2[order[1:]])</span><br><span class="line">        iy2 = np.minimum(y2[i], y2[order[1:]])</span><br><span class="line">        w = np.maximum(0.0, ix2-ix1+1)</span><br><span class="line">        h = np.maximum(0.0, iy2-iy1+1)</span><br><span class="line">        inter = w * h</span><br><span class="line">        ovr = inter / (areas[i] + areas[order[1:]] - inter)</span><br><span class="line">        inds = np.where(ovr &lt;= thresh)[0]</span><br><span class="line">        order = order[inds + 1]</span><br><span class="line">    <span class="built_in">return</span> boxes[np.require(keep), :]</span><br><span class="line"></span><br><span class="line"><span class="comment">#parse result</span></span><br><span class="line">def parse_result(out_put):</span><br><span class="line">    global num_classes</span><br><span class="line">    global num_anchors</span><br><span class="line">    global side</span><br><span class="line">    locations = side ** 2</span><br><span class="line">    boxes = np.zeros((num_anchors * locations, 6), dtype=np.float32)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(locations):</span><br><span class="line">        tmp_scores = out_put[i:num_classes*locations:locations]</span><br><span class="line">        max_class_ind = np.argsort(tmp_scores)[-1]</span><br><span class="line">        max_prob = np.max(tmp_scores)</span><br><span class="line">        obj_index = num_classes * locations + i</span><br><span class="line">        obj_scores = max_prob * out_put[obj_index:(obj_index+num_anchors*locations):locations]</span><br><span class="line">        coor_index = (num_classes + num_anchors) * locations + i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(num_anchors):</span><br><span class="line">           boxes[i*num_anchors+j][5] = max_class_ind</span><br><span class="line">           boxes[i*num_anchors+j][4] = obj_scores[j]</span><br><span class="line">           box_index = coor_index + j * 4 * locations</span><br><span class="line">           boxes[i*num_anchors+j][0] = (i % side + out_put[box_index + 0 * locations]) / <span class="built_in">float</span>(side)</span><br><span class="line">           boxes[i*num_anchors+j][1] = (i / side + out_put[box_index + 1 * locations]) / <span class="built_in">float</span>(side)</span><br><span class="line">           boxes[i*num_anchors+j][2] = out_put[box_index + 2 * locations] ** 2</span><br><span class="line">           boxes[i*num_anchors+j][3] = out_put[box_index + 3 * locations] ** 2</span><br><span class="line">    <span class="built_in">return</span> nms(boxes, 0.5)</span><br><span class="line"></span><br><span class="line"><span class="comment">#show or write result_picture</span></span><br><span class="line">def show_boxes(im_path, boxes, sthresh=0.5, hthresh=1, show=0):</span><br><span class="line">    <span class="built_in">print</span> (boxes.shape)</span><br><span class="line">    im = cv2.imread(im_path)</span><br><span class="line">    ori_w = im.shape[1]</span><br><span class="line">    ori_h = im.shape[0]</span><br><span class="line">    <span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">        <span class="keyword">if</span> box[4] &lt; sthresh:</span><br><span class="line">            <span class="built_in">continue</span></span><br><span class="line">        <span class="keyword">if</span> box[4] &gt; hthresh:</span><br><span class="line">            <span class="built_in">continue</span></span><br><span class="line">        <span class="built_in">print</span> (box)</span><br><span class="line">        box = box[:4]</span><br><span class="line">        x1 = max(0, int((box[0] - box[2] / 2.) * ori_w))</span><br><span class="line">        y1 = max(0, int((box[1] - box[3] / 2.) * ori_h))</span><br><span class="line">        x2 = min(ori_w - 1, int((box[0] + box[2] / 2.) * ori_w))</span><br><span class="line">        y2 = min(ori_h - 1, int((box[1] + box[3] / 2.) * ori_h))</span><br><span class="line">        cv2.rectangle(im, (x1, y1), (x2, y2), (0, 255, 255), 2)</span><br><span class="line">    name = os.path.split(im_path)[1].split(<span class="string">'.'</span>)[0]</span><br><span class="line">    <span class="keyword">if</span> show:</span><br><span class="line">        cv2.imshow(<span class="string">"out"</span>, im)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cv2.imwrite(<span class="string">"adam-out-n"</span>+name+<span class="string">'.jpg'</span>, im)</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict</span></span><br><span class="line">def predict(model, im_path):</span><br><span class="line">    <span class="comment"># image pre-processing</span></span><br><span class="line">    im = cv2.imread(im_path)</span><br><span class="line">    im = cv2.resize(im, (160, 160))</span><br><span class="line">    im = np.require(im.transpose((2, 0, 1)), dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward process...</span></span><br><span class="line">    model.blobs[<span class="string">'data'</span>].data[...] = im</span><br><span class="line">    out_blobs = model.forward()</span><br><span class="line">    </span><br><span class="line">    <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">    The structure of out_put is:</span></span><br><span class="line"><span class="string">    [n*n*class1,n*n*class2,...,n*n*class(i),n*n*score1,n*n*score2,n*n*(x,y,w,h)1,n*n*(x,y,w,h)2]</span></span><br><span class="line"><span class="string">    p.s. n is side</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    reg_out = out_blobs[<span class="string">"fc9"</span>]</span><br><span class="line">    boxes = parse_result(reg_out[0])</span><br><span class="line">    show_boxes(im_path, boxes, 0.2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    global net_proto</span><br><span class="line">    global model_path</span><br><span class="line">    global im_path</span><br><span class="line">    <span class="comment"># load net with model</span></span><br><span class="line">    model = caffe.Net(net_proto, model_path, caffe.TEST)</span><br><span class="line"></span><br><span class="line">    predict(model, im_path)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;本博文记录博主对caffe的初步理解以及yolo在caffe上的运行&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;一、数据处理篇&quot;&gt;&lt;a href=&quot;#一、数据处理篇&quot; class=&quot;headerlink&quot; title=&quot;一、数据处理篇&quot;&gt;&lt;/a&gt;一、数据处理
      
    
    </summary>
    
    
      <category term="caffe" scheme="http://yoursite.com/tags/caffe/"/>
    
      <category term="cv" scheme="http://yoursite.com/tags/cv/"/>
    
  </entry>
  
  <entry>
    <title>安装教程：Ubuntu16.04+CUDA9.0+CUDNN7.1+caffe(gpu)+opencv</title>
    <link href="http://yoursite.com/2018/12/28/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%EF%BC%9AUbuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/"/>
    <id>http://yoursite.com/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/</id>
    <published>2018-12-27T17:45:17.000Z</published>
    <updated>2018-12-28T04:15:44.447Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本教程适用于CUDA9.0+CUDNN7.1+OPENCV(3.4.0)</strong></p><h2 id="一、依赖包安装"><a href="#一、依赖包安装" class="headerlink" title="一、依赖包安装"></a>一、依赖包安装</h2><p> 在Ubuntu的Terminal中输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler</span><br><span class="line">sudo apt-get install --no-install-recommends libboost-all-dev</span><br><span class="line">sudo apt-get install libopenblas-dev liblapack-dev libatlas-base-dev</span><br><span class="line">sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev</span><br></pre></td></tr></table></figure></p><h2 id="二、驱动安装-Nvidia-384-X版本的驱动"><a href="#二、驱动安装-Nvidia-384-X版本的驱动" class="headerlink" title="二、驱动安装(Nvidia 384.X版本的驱动)"></a>二、驱动安装(Nvidia 384.X版本的驱动)</h2><p>方式一<br>在Terminal输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update  </span><br><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa </span><br><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install nvidia-384 </span><br><span class="line">sudo apt-get install mesa-common-dev </span><br><span class="line">sudo apt-getinstall freeglut3-dev</span><br></pre></td></tr></table></figure></p><p>方式二<br>直接在Ubuntu中的System Settings–&gt;Software&amp;Updates中的additional drivers：<br><img src="/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/1.png" alt="效果图"><br>驱动安装成功的标志：<br><img src="/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/2.png" alt="效果图"></p><h2 id="三、CUDA9-0安装"><a href="#三、CUDA9-0安装" class="headerlink" title="三、CUDA9.0安装"></a>三、CUDA9.0安装</h2><p>请通过官网下载CUDA安装文件（.run文件)，运行文件命令如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先CD至.run文件的文件夹，再运行该命令</span></span><br><span class="line">sudo sh cuda_9.0.176_384.81_linux.run</span><br></pre></td></tr></table></figure></p><p>先按q直接跳过阅读协议，然后accept，后面的除了Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?这样的选n,其它的有y选y，或者直接回车默认<br>检查一下环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gedit ~/.bashr</span><br></pre></td></tr></table></figure></p><p>末尾添加<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#cuda</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-9.0/lib64/:<span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-9.0/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></p><p>然后激活<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></p><p>检验安装是否完整：<br><img src="/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/3.png" alt="效果图"></p><h2 id="四、CUDNN7-1安装"><a href="#四、CUDNN7-1安装" class="headerlink" title="四、CUDNN7.1安装"></a>四、CUDNN7.1安装</h2><p>请通过官网下载CUDNN安装文件（.tgz文件)，直接在Terminal中cd至所在文件夹，运行以下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf cudnn-9.0-linux-x64-v7.1.tgz </span><br><span class="line">sudo cp cuda/include/cudnn.h /usr/<span class="built_in">local</span>/cuda/include/ </span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/<span class="built_in">local</span>/cuda/lib64/ -d </span><br><span class="line">sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/include/cudnn.h </span><br><span class="line">sudo chmod a+r /usr/<span class="built_in">local</span>/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure></p><p>检验是否安装完整：<br><img src="/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/4.png" alt="效果图"></p><h2 id="五、Opencv源码编译安装"><a href="#五、Opencv源码编译安装" class="headerlink" title="五、Opencv源码编译安装"></a>五、Opencv源码编译安装</h2><p>将下载好的opencv源码（.zip文件）解压缩至home文件夹下，然后在Terminal中输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/opencv-3.4.1</span><br><span class="line">mkdir build </span><br><span class="line"><span class="built_in">cd</span> build </span><br><span class="line">cmake -D CMAKE_BUILD_TYPE=Release .. </span><br><span class="line">sudo make -j8</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure></p><p>安装完后检验:<br><img src="/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/5.png" alt="效果图"></p><h2 id="六、Caffe安装"><a href="#六、Caffe安装" class="headerlink" title="六、Caffe安装"></a>六、Caffe安装</h2><p>此处我直接安装到home目录，执行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~ </span><br><span class="line">git <span class="built_in">clone</span> https://github.com/BVLC/caffe.git <span class="comment">#开始clone</span></span><br></pre></td></tr></table></figure></p><p>等待下载结束，下载结束后在你的home路径下会存在，caffe文件夹。接下来进入caffe并开始配置caffe，配置如下:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp Makefile.config.example Makefile.config</span><br><span class="line">sudo gedit Makefile.config <span class="comment">#或者sudo vim Makefile.config</span></span><br></pre></td></tr></table></figure></p><p>修改Makefile.config内容：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">将：</span><br><span class="line"><span class="comment">#USE_CUDNN := 1</span></span><br><span class="line">修改为： </span><br><span class="line">USE_CUDNN := 1</span><br><span class="line"></span><br><span class="line">将：</span><br><span class="line"><span class="comment">#OPENCV_VERSION := 3 </span></span><br><span class="line">修改为： </span><br><span class="line">OPENCV_VERSION := 3</span><br><span class="line"></span><br><span class="line">将：</span><br><span class="line"><span class="comment">#WITH_PYTHON_LAYER := 1</span></span><br><span class="line">修改为</span><br><span class="line">WITH_PYTHON_LAYER := 1</span><br><span class="line"></span><br><span class="line">将：</span><br><span class="line">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/<span class="built_in">local</span>/include</span><br><span class="line">LIBRARY_DIRS := $(PYTHON_LIB) /usr/<span class="built_in">local</span>/lib /usr/lib</span><br><span class="line">修改为：</span><br><span class="line">INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/<span class="built_in">local</span>/include /usr/include/hdf5/serial</span><br><span class="line">LIBRARY_DIRS := $(PYTHON_LIB) /usr/<span class="built_in">local</span>/lib /usr/lib /usr/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/hdf5/serial</span><br><span class="line"></span><br><span class="line">将</span><br><span class="line"><span class="comment"># CUDA architecture setting: going with all of them.</span></span><br><span class="line"><span class="comment"># For CUDA &amp;lt; 6.0, comment the *_50 through *_61 lines for compatibility.</span></span><br><span class="line"><span class="comment"># For CUDA &amp;lt; 8.0, comment the *_60 and *_61 lines for compatibility.</span></span><br><span class="line"><span class="comment"># For CUDA &amp;gt;= 9.0, comment the *_20 and *_21 lines for compatibility.</span></span><br><span class="line">CUDA_ARCH := -gencode arch=compute_20,code=sm_20 \</span><br><span class="line">           -gencode arch=compute_20,code=sm_21 \</span><br><span class="line">           -gencode arch=compute_30,code=sm_30 \</span><br><span class="line">           -gencode arch=compute_35,code=sm_35 \</span><br><span class="line">           -gencode arch=compute_50,code=sm_50 \</span><br><span class="line">           -gencode arch=compute_52,code=sm_52 \</span><br><span class="line">           -gencode arch=compute_60,code=sm_60 \</span><br><span class="line">           -gencode arch=compute_61,code=sm_61 \</span><br><span class="line">           -gencode arch=compute_61,code=compute_61</span><br><span class="line"></span><br><span class="line">改为：</span><br><span class="line"><span class="comment"># CUDA architecture setting: going with all of them.</span></span><br><span class="line"><span class="comment"># For CUDA &amp;lt; 6.0, comment the *_50 through *_61 lines for compatibility.</span></span><br><span class="line"><span class="comment"># For CUDA &amp;lt; 8.0, comment the *_60 and *_61 lines for compatibility.</span></span><br><span class="line"><span class="comment"># For CUDA &amp;gt;= 9.0, comment the *_20 and *_21 lines for compatibility.</span></span><br><span class="line">CUDA_ARCH := -gencode arch=compute_30,code=sm_30 \</span><br><span class="line">           -gencode arch=compute_35,code=sm_35 \</span><br><span class="line">           -gencode arch=compute_50,code=sm_50 \</span><br><span class="line">           -gencode arch=compute_52,code=sm_52 \</span><br><span class="line">           -gencode arch=compute_60,code=sm_60 \</span><br><span class="line">           -gencode arch=compute_61,code=sm_61 \</span><br><span class="line">           -gencode arch=compute_61,code=compute_61</span><br></pre></td></tr></table></figure></p><p>修改Makefile文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">将：</span><br><span class="line">NVCCFLAGS +=-ccbin=$(CXX) -Xcompiler-fPIC $(COMMON_FLAGS)</span><br><span class="line">替换为：</span><br><span class="line">NVCCFLAGS += -D_FORCE_INLINES -ccbin=$(CXX) -Xcompiler -fPIC $(COMMON_FLAGS)</span><br><span class="line"></span><br><span class="line">将：</span><br><span class="line">LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_hl hdf5</span><br><span class="line">改为：</span><br><span class="line">LIBRARIES += glog gflags protobuf boost_system boost_filesystem m hdf5_serial_hl hdf5_serial</span><br></pre></td></tr></table></figure></p><p>配置完好之后开始编译：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> caffe</span><br><span class="line">sudo make clean</span><br><span class="line">sudo make all <span class="comment">#或者make all -j4(代表4核，或者j8)</span></span><br><span class="line">sudo make <span class="built_in">test</span></span><br><span class="line">sudo make runtest <span class="comment">#或者sudo make runtest -j8</span></span><br><span class="line">sudo make pycaffe</span><br></pre></td></tr></table></figure></p><p>检验是否安装完整：<br><img src="/2018/12/28/安装教程：Ubuntu16-04-CUDA9-0-CUDNN7-1-caffe-gpu-opencv/6.png" alt="效果图"><br>所有的test中，如果编译不报错，则说明安装完整。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;本教程适用于CUDA9.0+CUDNN7.1+OPENCV(3.4.0)&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;一、依赖包安装&quot;&gt;&lt;a href=&quot;#一、依赖包安装&quot; class=&quot;headerlink&quot; title=&quot;一、依赖包安装&quot;&gt;&lt;/a&gt;一、依赖
      
    
    </summary>
    
    
      <category term="caffe" scheme="http://yoursite.com/tags/caffe/"/>
    
  </entry>
  
</feed>
